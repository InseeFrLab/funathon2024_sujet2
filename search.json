[
  {
    "objectID": "index.html#objectif",
    "href": "index.html#objectif",
    "title": "Un tableau de bord du trafic aérien avec  ou ",
    "section": "1.1 Objectif",
    "text": "1.1 Objectif\nL’objectif de ce tutoriel est d’amener, pas à pas, à la conception voire à la mise à disposition d’un tableau de bord (dashboard) du trafic aérien avec  ou . Ce tutoriel est également l’occasion d’apprendre quelques bonnes pratiques pour les projets  et . Une démonstration de cette application est disponible sur\n\nhttps://rplane-dashboard.kub.sspcloud.fr/ () ;\nhttps://pylot-dashboard.kub.sspcloud.fr/ ().\n\nL’objectif est de construire progressivement cette application en suivant les étapes logiques du déroulement d’un projet de développement d’application interactive : découverte et exploration des données, création de statistiques descriptives et de visualisations simples sur un jeu de données, extension du nombre de visualisations accessibles par la création d’une application.\nL’objectif secondaire de ce tutoriel est de faire découvrir quelques bonnes pratiques de programmation avec  ou  afin de rendre les projets plus fiables, évolutifs et lisibles. Comme vous pourrez le faire au cours de celui-ci, la différence entre ces deux langages est assez minime. L’un des objectifs de ce tutoriel est de vous amener à structurer votre projet selon la norme suivante:\n\n\n\n\n\n\n\n(a) Environnement mal structuré\n\n\n\n\n\n\n\n(b) Environnement bien structuré\n\n\n\n\nFigure 1: L’environnement vers lequel on désire converger\n\n\nLes exercices de conception pas à pas de l’application s’adressent aussi bien à des débutants qu’à des utilisateurs plus avancés. La mise à disposition, c’est-à-dire la mise en production de cette application, fait toutefois appel à des concepts et outils plus avancés et est donc moins accessible à des débutants.\n\n\n\n\n\n\nNote\n\n\n\nAfin de se concentrer sur la démarche, cette application interactive présentera un nombre limité de fonctionnalités.\nSi vous disposez de temps supplémentaire, n’hésitez pas à ajouter des fonctionnalités à celle-ci et à les proposer pour un ajout dans la galerie du site web du funathon (inseefrlab.github.io/funathon2024/)."
  },
  {
    "objectID": "index.html#pourquoi-développer-une-application-interactive",
    "href": "index.html#pourquoi-développer-une-application-interactive",
    "title": "Un tableau de bord du trafic aérien avec  ou ",
    "section": "1.2 Pourquoi développer une application interactive ?",
    "text": "1.2 Pourquoi développer une application interactive ?\nCette question peut apparaître naïve. Pourtant, elle mérite d’être posée car elle permet de réfléchir:\n\nà l’objectif de l’application ;\nà son public cible.\n\nCette réflexion devrait être menée systématiquement car elle guide les choix techniques ultérieurs et la répartition des tâches entre les différents profils pouvant intervenir dans la vie du projet s’il est mis en production (statisticien ou data scientist, équipes informatiques…).\n\n1.2.1 Une valorisation de données rapide et attractive\nEn général, on fait de la visualisation de données car les sources de données exploitées présentent tellement de dimensions pouvant intéresser un utilisateur qu’il est plus pertinent de le laisser explorer les données que de définir pour lui les statistiques à mettre en avant. L’interactivité permise par les sites web est particulièrement adaptée pour cela : le fait d’afficher ou masquer des visualisations en fonction de choix de l’utilisateur évite de noyer l’information par rapport à des supports figés.\nLes frameworks Shiny (), Streamlit ou Dash () permettent de rapidement mettre en oeuvre ce type de site web. Pour une phase de construction d’un prototype, c’est un choix technique intéressant qui peut provoquer l’effet wahou attendu pour lancer le projet à plus grande échelle. En effet, ces solutions techniques permettent, avec les outils bien connus des praticiens de la donnée ( ou ) de créer rapidement un site web fonctionnel, ergonomique et effectuant des opérations en fonction d’actions de l’utilisateur sur la page web. Tout ceci sans avoir à maîtriser des notions complexes de développement web.\n\n\n1.2.2 Une mise à disposition parfois complexe\nNéanmoins, passée cette phase d’expérimentation, le partage de ces applications, au-delà d’un partage d’écran pour des démonstrations, n’est pas toujours évident (d’où le fait, nous y reviendrons, que la dernière partie de ce tutoriel s’adresse plutôt à un niveau expert). Cette difficulté est due au fait qu’assurer le bon fonctionnement d’un site web pérenne requiert la maîtrise de notions complexes, qui ne sont pas nécessaires au cours de la phase d’expérimentation. Celles-ci dépassent néanmoins le champ de compétence des statisticiens ou data scientists.\nAutrement dit, si le projet a l’ambition d’être partagé à une audience large qui n’a pas les compétences techniques pour faire tourner elle-même le code, il convient de prendre en compte le fait qu’il faudra dans l’équipe projet des compétencess spécifiques de développement web. Si le projet est expérimental, c’est moins un problème : Shiny, Dash ou Streamlit permettront d’avoir rapidement un prototype viable.\nIl existe heureusement des solutions techniques plus simples à mettre en oeuvre que Shiny, Streamlit ou Dash. Les sites web statiques font partie de cet éventail des possibles et représentent souvent une alternative pertinente aux applications interactives à condition qu’ils soient bien pensés. Ils sont notamment pertinents pour les applications de visualisation de données où cette dernière est déjà préparée en amont. Avoir un serveur R ou Python se justifie en effet si des étapes complexes de structuration de données interviennent. Inversement, si aucun traitement de données complexe n’est nécessaire, un simple enrobage avec un constructeur de site comme Quarto peut suffire, à condition que les productions graphiques ne soient pas trop complexes à créer. Pour des sites faisant intervenir des interactions multiples entre actions d’un utilisateur (bouton, menu déroulant, etc. ) et affichage, il faudra recourir à du Javascript (technologie utilisée par les sites spécialisés dans la dataviz), ce qui fait, à nouveau, appel à des compétences qui dépassent celles des data scientists ou statisticiens classiques.\nEn résumé, les éléments ci-dessus ont vocation à servir de mise en garde. Shiny, Dash ou Streamlit sont d’excellents outils techniques lorsqu’ils sont utilisés à bon escient. Ceci dit, leur simplicité d’usage ne dispense pas de se poser des questions cruciales comme celles du cycle de vie du projet, du public cible ou encore de la compétence des équipes amenées à maintenir le projet s’il perdure au-delà d’une phase d’expérimentation.\n\n\n\n\n\n\nSite statique vs application réactive\n\n\n\n\n\nLa distinction principale entre ces deux approches est qu’elles s’appuient sur des serveurs différents. Un site statique repose sur un serveur web là où Shiny/Streamlit s’appuient sur des serveurs classiques en backend. La différence principale entre ces deux types de serveurs réside principalement dans leur fonction et leur utilisation :\n\nUn serveur web est spécifiquement conçu pour stocker, traiter et livrer des pages web aux clients. Cela inclut des fichiers HTML, CSS, JavaScript, images, etc. Les serveurs web écoutent les requêtes HTTP/HTTPS provenant des navigateurs des utilisateurs et y répondent en envoyant les données demandées.\nUn serveur backend classique est conçu pour effectuer des opérations en réponse à un front, en l’occurrence une page web. Dans le contexte d’une application Streamlit (resp. Shiny), il s’agit d’un serveur avec l’environnement Python (resp. R) ad hoc pour exécuter le code nécessaire à répondre à toute action d’un utilisateur de l’application."
  },
  {
    "objectID": "index.html#préliminaire-récupérer-le-projet-squelette-avec-git-fa-brands-git-alt",
    "href": "index.html#préliminaire-récupérer-le-projet-squelette-avec-git-fa-brands-git-alt",
    "title": "Un tableau de bord du trafic aérien avec  ou ",
    "section": "2.1 Préliminaire : récupérer le projet squelette avec Git ",
    "text": "2.1 Préliminaire : récupérer le projet squelette avec Git \nSi vous disposez d’un compte sur le sspcloud, la méthode recommandée pour se lancer dans ce tutoriel est de cliquer sur le bouton suivant\n\n\n\n\nLa démarche de récupération a été expliquée au cours de la présentation de l’environnement technique. Voici, en résumé, les gestes à faire:\n\nForker le dépôt  InseeFrLab/funathon2024_sujet2\nCliquer sur le bouton ci-dessous:\n\n\n\n\n\n\nSur la page SSPCloud qui s’ouvre, changer l’URL indiqué dans l’onglet Git pour mettre celui de votre fork\n\nRevoir la vidéo de présentation sur https://inseefrlab.github.io/funathon2024 (à démarrer à partir de 1h29mn)\n\n\nLa démarche de récupération est assez similaire à celle expliquée pour . Voici, en résumé, les gestes à faire:\n\nForker le dépôt  InseeFrLab/funathon2024_sujet2\nCliquer sur le bouton ci-dessous:\n\n\n\n\n\n\nSur la page SSPCloud qui s’ouvre, changer l’URL indiqué dans l’onglet Git pour mettre celui de votre fork\n\nRevoir la vidéo de présentation sur https://inseefrlab.github.io/funathon2024 (à démarrer à partir de 1h29mn)\n\n\n\nSi vous avez utilisé le lien de lancement rapide mis à disposition sur la page inseefrlab.github.io/funathon2024/ ou ci-dessus ☝️, vous pouvez sauter l’étape de récupération du modèle de projet avec Git , cela a été fait automatiquement lors de la création de votre environnement RStudio ou VSCode. Cela ne vous dispense pas de faire du Git tout au long du tutoriel 😺, c’est une bonne pratique, même sur des projets ponctuels ou vous êtes seuls à travailler.\n\n\n\n\n\n\nRécupérer le projet si vous n’avez pas utilisé le bouton proposé\n\n\n\n\n\n\n\n\n\n\nInterface graphiqueDepuis le terminal\n\n\nLa fiche utilitR sur l’utilisation de Git explicite la démarche générale pour récupérer du code grâce à Git. Il est recommandé de lire celle-ci si vous n’êtes pas familier de Git.\nLes étapes suivantes permettront de récupérer le projet:\n1️⃣ En premier lieu, dans RStudio, créer un nouveau projet et sélectionner Version Control.\n\n2️⃣ Choisir Git, ce qui devrait ouvrir une fenêtre similaire à celle ci-dessous:\n\n3️⃣ Dans la fenêtre Repository URL, passer la valeur\nhttps://github.com/inseefrlab/funathon2024_sujet2.git\nlaisser les valeurs par défaut qui viennent ensuite et créer le projet.\n\n\nAprès avoir ouvert un terminal dans RStudio, faire\ngit clone https://github.com/inseefrlab/funathon2024_sujet2.git\npuis, dans l’explorateur de fichiers (fenêtre en bas à droite), cliquer sur le fichier RTraffic.Rproj pour ouvrir le projet.\n\n\n\n\n\n\nOuvrir un terminal depuis VSCode (Terminal &gt; New Terminal).\nRécupérer, sur la page d’accueil de votre dépôt, l’url du dépôt distant. Il prend la forme suivante\n\nhttps://github.com/&lt;username&gt;/&lt;reponame&gt;.git\n\nDans le terminal, taper\n\ngit clone repo_url\noù repo_url est l’URL de votre fork"
  },
  {
    "objectID": "index.html#se-placer-dans-lenvironnement-du-projet",
    "href": "index.html#se-placer-dans-lenvironnement-du-projet",
    "title": "Un tableau de bord du trafic aérien avec  ou ",
    "section": "2.2 Se placer dans l’environnement du projet",
    "text": "2.2 Se placer dans l’environnement du projet\n\n\n\n\nA la racine du projet, on trouve notamment le fichier RTraffic.Rproj. Il s’agit d’un fichier de projet RStudio. Lorsqu’on travaille sur du code  avec RStudio, il est généralement préférable de travailler dans le cadre d’un projet.\nEntre autres raisons, évoquées dans la documentation utilitR, cela favorise la reproductibilité: lorsqu’on se situe dans un projet RStudio, tous les chemins peuvent être définis de manière relative (à la racine du projet) plutôt que de manière absolue (à la racine de la machine). Ainsi, le projet s’exécutera de la même manière qu’il soit exécuté depuis une machine Windows ou Linux par exemple, avec des noms d’utilisateurs différents ou s’ils se situent dans des dossiers différents au sein de “Mes Documents”.\n\n\n\n\n\n\nPlus de détails dans utilitR\n\n\n\n\n\nPour plus de détails sur les bénéfices d’utiliser les projets RStudio ou leur utilisation en pratique, n’hésitez pas à consulter la fiche utilitR dédiée.\n\n\n\n\n\nLes utilisateurs de  connaissent deux environnements de travail très différents: la ligne de commande pour exécuter des scripts ou les notebooks Jupyter pour avoir un environnement interactif.\nLes seconds sont pratiques pour prototyper et expérimenter. Mais ils ne sont pas faits pour construire des applications. Nous proposons donc la méthode de travail suivante:\n\nCréer un Jupyter Notebook à la racine du projet (au même niveau que le README.md)1. Celui-ci sera votre espace pour écrire du code expérimental. Lorsqu’il sera fonctionnel, vous pourrez le reporter dans des scripts comme indiqués dans les consignes.\nDans un terminal, faire cd funathon2024_sujet2 (ou remplacer par le nom de dossier différent si vous l’avez changé). C’est dans ce terminal que vous testerez vos scripts. Pour ouvrir un terminal, il suffit de cliquer sur le menu VScode en haut à gauche (les trois petites barres horizontales), puis Terminal &gt; New Terminal."
  },
  {
    "objectID": "index.html#architecture-du-projet",
    "href": "index.html#architecture-du-projet",
    "title": "Un tableau de bord du trafic aérien avec  ou ",
    "section": "2.3 Architecture du projet",
    "text": "2.3 Architecture du projet\nLe projet récupéré comporte de nombreux fichiers. Nous allons progressivement les découvrir dans ce tutoriel. A l’heure actuelle, on peut se concentrer sur les fichiers suivants:\n\n\n\n\nfunathon_sujet2/\n├── renv.lock\n├── correction/R/\n├── correction/global.R\n├── correction/server.R\n└── correction/ui.R\nLe premier fichier (renv.lock) correspond à la liste des packages nécessaires pour reproduire l’environnement. Il a été généré automatiquement grâce à un écosystème renv particulièrement adapté pour assurer la reproductibilité de projets  (voir la suite).\nLes fichiers server.R et ui.R constituent le coeur de notre application Shiny. Ils représentent, respectivement, le moteur de calcul (le serveur) et l’interface utilisateur de notre application. Nous reviendrons sur ce concept. Le fichier global.R stocke un certain nombre d’objets utiles à l’application mais qui n’ont pas besoin d’être recalculés à chaque action sur l’interface graphique. Nous allons progressivement construire ces fichiers pendant les différents exercices. De nombreuses fonctions sont reportées dans les fichiers au sein du dossier R/.\n\n\nObserver la composition de ce fichier (100 premières lignes)\n\n\n\nrenv.lock\n\n{\n  \"R\": {\n    \"Version\": \"4.3.3\",\n    \"Repositories\": [\n      {\n        \"Name\": \"CRAN\",\n        \"URL\": \"https://packagemanager.posit.co/cran/latest\"\n      }\n    ]\n  },\n  \"Packages\": {\n    \"BH\": {\n      \"Package\": \"BH\",\n      \"Version\": \"1.84.0-0\",\n      \"Source\": \"Repository\",\n      \"Repository\": \"CRAN\",\n      \"Hash\": \"a8235afbcd6316e6e91433ea47661013\"\n    },\n    \"DBI\": {\n      \"Package\": \"DBI\",\n      \"Version\": \"1.2.2\",\n      \"Source\": \"Repository\",\n      \"Repository\": \"CRAN\",\n      \"Requirements\": [\n        \"R\",\n        \"methods\"\n      ],\n      \"Hash\": \"164809cd72e1d5160b4cb3aa57f510fe\"\n    },\n    \"DT\": {\n      \"Package\": \"DT\",\n      \"Version\": \"0.33\",\n      \"Source\": \"Repository\",\n      \"Repository\": \"RSPM\",\n      \"Requirements\": [\n        \"crosstalk\",\n        \"htmltools\",\n        \"htmlwidgets\",\n        \"httpuv\",\n        \"jquerylib\",\n        \"jsonlite\",\n        \"magrittr\",\n        \"promises\"\n      ],\n      \"Hash\": \"64ff3427f559ce3f2597a4fe13255cb6\"\n    },\n    \"KernSmooth\": {\n      \"Package\": \"KernSmooth\",\n      \"Version\": \"2.23-22\",\n      \"Source\": \"Repository\",\n      \"Repository\": \"CRAN\",\n      \"Requirements\": [\n        \"R\",\n        \"stats\"\n      ],\n      \"Hash\": \"2fecebc3047322fa5930f74fae5de70f\"\n    },\n    \"MASS\": {\n      \"Package\": \"MASS\",\n      \"Version\": \"7.3-60.0.1\",\n      \"Source\": \"Repository\",\n      \"Repository\": \"CRAN\",\n      \"Requirements\": [\n        \"R\",\n        \"grDevices\",\n        \"graphics\",\n        \"methods\",\n        \"stats\",\n        \"utils\"\n      ],\n      \"Hash\": \"b765b28387acc8ec9e9c1530713cb19c\"\n    },\n    \"Matrix\": {\n      \"Package\": \"Matrix\",\n      \"Version\": \"1.6-5\",\n      \"Source\": \"Repository\",\n      \"Repository\": \"CRAN\",\n      \"Requirements\": [\n        \"R\",\n        \"grDevices\",\n        \"graphics\",\n        \"grid\",\n        \"lattice\",\n        \"methods\",\n        \"stats\",\n        \"utils\"\n      ],\n      \"Hash\": \"8c7115cd3a0e048bda2a7cd110549f7a\"\n    },\n    \"R6\": {\n      \"Package\": \"R6\",\n      \"Version\": \"2.5.1\",\n      \"Source\": \"Repository\",\n      \"Repository\": \"RSPM\",\n      \"Requirements\": [\n        \"R\"\n      ],\n      \"Hash\": \"470851b6d5d0ac559e9d01bb352b4021\"\n    },\n    \"RColorBrewer\": {\n\n\n\n\nfunathon_sujet2/\n├── requirements.txt\n├── correction/src/\n└── correction/app.py\nLe premier fichier (requirements.txt) correspond à la liste des packages nécessaires pour reproduire l’environnement. Il s’agit d’un outil particulièrement adapté pour assurer la reproductibilité de projets  (voir la suite).\nLe fichier app.py constitue le coeur de notre application Streamlit. Ils représentent, respectivement, le moteur de calcul (le serveur) et l’interface utilisateur de notre application. Nous reviendrons sur ce concept. Par ailleurs, de nombreuses fonctions utiles pour l’application sont reportées dans les fichiers au sein du dossier src/ (abréviation de “source”).\n\n\nObserver la composition de ce fichier\n\n\n\nrequirements.txt\n\npandas\ngeopandas\npyyaml\nplotly\nplotnine\ngreat_tables\nfolium\nstreamlit\nstreamlit-folium"
  },
  {
    "objectID": "index.html#installer-les-packages-nécessaires-pour-ce-tutoriel",
    "href": "index.html#installer-les-packages-nécessaires-pour-ce-tutoriel",
    "title": "Un tableau de bord du trafic aérien avec  ou ",
    "section": "2.4 Installer les packages nécessaires pour ce tutoriel",
    "text": "2.4 Installer les packages nécessaires pour ce tutoriel\n\n2.4.1 Principe\nPour progresser dans ce tutoriel, un certain nombre de packages doivent être installés. Sans eux, même avec le code de l’application, vous ne serez pas en mesure de reproduire celle-ci.\nLes bonnes pratiques pour la gestion de l’environnement sont assez proches en  et . Le principal général est qu’il existe des outils qui permettent à un utilisateur de lister l’ensemble des packages dans son environnement avec leur version. Grâce à cette liste, d’autres personnes pourront reproduire l’application si elles disposent des mêmes inputs (le code, les données…).\nEn effet, il est important de voir l’application comme le résultat de la combinaison de plusieurs ingrédients. Dans notre cas, nous en avons trois:\n\nDu code  ou  : celui-ci a été récupéré grâce à Git lors du lancement du projet;\nDes éléments de configuration:\n\nle fichier renv.lock () ou requirements.txt () qui permettra de reconstruire notre environnement à l’identique grâce à des outils adaptés2;\nle fichier sources.yaml qui liste l’emplacement des sources sur le site data.gouv.\n\nDes données : nous évoquerons celles-ci lors de la prochaine partie.\n\n\n\n\nIllustration du principe de séparation du code, des données et de la configuration\n\n\nDe manière générale, c’est une bonne pratique de structurer son projet comme une combinaison de ces facteurs. Cela vous amènera à faire des projets plus reproductibles mais aussi à la structure plus lisible.\nPour les utilisateurs de R, la formation de l’Insee aux bonnes pratiques consacre une partie aux environnements reproductibles avec renv. Pour les utilisateurs de Python, le cours de mise en production de projets data science consacre un chapitre au sujet.\n\n\n2.4.2 Créer l’environnement\nSi vous avez déjà tenté de partager un code qui fonctionnait chez vous, il est presque certain que la personne ayant voulu le réutiliser a rencontré une erreur si elle a tenté de le faire tourner. C’est tout à fait normal car vous avez distribué votre code, éventuellement vos données, mais pas le troisième pilier de l’image précédente, à savoir la configuration de l’environnement dans lequel votre code fonctionnait. La solution la plus fiable, mais peu pratique, serait de donner votre ordinateur à la personne qui tente de réutiliser votre code. En livrant votre ordinateur, vous fournissez votre environnement de travail mais également beaucoup d’éléments supplémentaires qui ne sont pas indispensables à l’application.\nUne solution plus simple est de fournir les spécifications qui ont permis à votre code de fonctionner. Dans un monde idéal, il s’agit de fournir la liste des packages et leur version. Si la personne à qui vous partagez votre code et vos données a cette même liste de versions de packages, et pas de packages supplémentaires venant polluer l’environnement, les chances d’avoir la même application que vous sont très élevées.\nLes solutions techniques pour restaurer un environnement  et  sont légèrement différentes et sont décrites ci-dessous.\n\n\n\n\nrenv est un gestionnaire de packages qui permet de faire ces deux opérations :\n\nEnregistrer la liste de packages après avoir fait tourner un code\nRestaurer l’environnement à partir de cette liste\n\nEn l’occurrence, pour vous, l’important est le second point: pouvoir recréer l’environnement nécessaire au bon fonctionnement de l’application. Ceci est très simple grâce à la commande\n\n\nA lancer dans la console R\n\nrenv::restore()\n\nCette commande doit être lancée depuis la console R ouverte dans le projet qui a été récupéré3. L’environnement créé n’est pas figé. Il est tout à fait possible, ensuite, d’installer des packages supplémentaires par le biais de install.packages. L’environnement proposé par notre fichier renv.lock est le minimum requis pour reproduire l’application mais ce n’est pas un environnement figé. Si vous ajoutez des packages utiles pour votre application, avant la phase de mise en production, n’oubliez pas de faire renv::snapshot() pour mettre à jour le fichier renv.lock (c’est le point 1. évoqué précédemment).\n\n\n\n\n\n\nCe que renv évite\n\n\n\n\n\nOn retrouve parfois sur internet un code similaire à celui-ci :\n# A ne pas reproduire chez vous 😨\nif (!requireNamespace(\"dplyr\", quietly = TRUE)) {\n  install.packages(\"dplyr\")\n}\nC’est une gestion artisanale de l’environnement qui n’est pas conseillée. renv sera plus simple et plus fiable. De manière générale, ce n’est pas une bonne pratique de gérer l’installation des packages dans le script. En effet, c’est un élément de configuration et, comme nous l’avons dit, celle-ci doit se faire en dehors du script.\n\n\n\nMaintenant que nous disposons d’un environnement fonctionnel, nous pouvons avancer sur la conception du projet. La première étape est d’explorer les jeux de données que nous utiliserons dans l’application.\n\n\nPour faire les choses bien, il faudrait repartir d’un environnement vierge et installer toutes les dépendances du projet (comme le fait la solution ).\nNéanmoins, si vous êtes sur le SSPCloud, c’est presque de l’excès de zèle de faire cela car l’application a été développé à partir de l’environnement du SSPCloud duquel elle ne diverge que très peu. Il suffit donc d’ajouter à l’environnement existant un nombre restreint de packages qui sont listés dans requirements.txt.\nDans le terminal, il suffit donc de faire un pip install adéquat:\npip install -r requirements.txt\n\n\n\n\n\n\nCe que ce fichier requirements.txt évite\n\n\n\n\n\nOn retrouve parfois dans des notebooks partagés sur internet un code similaire à celui-ci :\n# A ne pas reproduire chez vous 😨\n!pip install geopandas\nvoire parfois dans des scripts, ce type de code:\n# A ne pas reproduire chez vous 😨\nimport subprocess\nsubprocess.run([\"pip install geopandas\"]) \nC’est une gestion artisanale de l’environnement qui n’est pas conseillée. De manière générale, ce n’est pas une bonne pratique de gérer l’installation des packages dans le script. En effet, c’est un élément de configuration et, comme nous l’avons dit, celle-ci doit se faire en dehors du script."
  },
  {
    "objectID": "index.html#objectifs",
    "href": "index.html#objectifs",
    "title": "Un tableau de bord du trafic aérien avec  ou ",
    "section": "3.1 Objectifs",
    "text": "3.1 Objectifs\nDans cette partie, vous allez explorer les données utilisées pour construire le tableau de bord, avec trois objectifs:\n\nvous familiariser avec les sources statistiques sur le trafic aérien;\ndévelopper des fonctions permettant d’importer automatiquement ces données;\ndécouvrir comment vous pouvez organiser ces fonctions pour qu’elles puissent être facilement utilisées par l’application web (spoiler alert: c’est là que le dossier R/ ou src/ va servir)."
  },
  {
    "objectID": "index.html#sources",
    "href": "index.html#sources",
    "title": "Un tableau de bord du trafic aérien avec  ou ",
    "section": "3.2 Sources",
    "text": "3.2 Sources\nLes sources statistiques utilisées dans ce tutoriel sont listées dans le fichier sources.yaml. Il y a quatre sources différentes:\n\nLe trafic au niveau de chaque aéroport (format CSV);\nLe nombre de passagers pour différentes liaisons (format CSV);\nLe trafic pour différentes compagnies (format CSV);\nLes localisations des aéroports (format geojson).\n\nUne bonne pratique, lorsqu’on utilise plusieurs sources, est de lister celles-ci dans un fichier YAML plutôt que de les inscrire en brut dans le code. Ce dernier sera plus lisible grâce à cette approche.\n\n\nVoir le fichier sources.yml\n\n\n\nsources.yml\n\n# Jeux de données \n# https://www.data.gouv.fr/fr/datasets/trafic-aerien-commercial-mensuel-francais-par-paire-daeroports-par-sens-depuis-1990/\n\nairports:\n  2018: \"https://www.data.gouv.fr/fr/datasets/r/3b7646ea-276c-4c9b-8151-1e96af2adbf9\"\n  2019: \"https://www.data.gouv.fr/fr/datasets/r/e8efa154-045e-4f8f-a1d7-76a39fa03b7b\"\n  2020: \"https://www.data.gouv.fr/fr/datasets/r/6717f107-be00-4b4b-9706-fa0e5190fb69\"\n  2021: \"https://www.data.gouv.fr/fr/datasets/r/2f9f6e54-e2d7-4e85-b811-2e5e68fa5bca\"\n  2022: \"https://www.data.gouv.fr/fr/datasets/r/f1bd931e-c99e-41ce-865e-9e9785c903ec\"\nliaisons:\n  2018: \"https://www.data.gouv.fr/fr/datasets/r/9c5354ad-31cb-4217-bc88-fb7c9be22655\"\n  2019: \"https://www.data.gouv.fr/fr/datasets/r/0c0a451e-983b-4f06-9627-b5ff1bccd2fc\"\n  2020: \"https://www.data.gouv.fr/fr/datasets/r/dad30bed-7276-4a67-a1ab-a856e6e01788\"\n  2021: \"https://www.data.gouv.fr/fr/datasets/r/bbf6492d-86ac-43a0-9260-7df2ffdb5a77\"\n  2022: \"https://www.data.gouv.fr/fr/datasets/r/af8950bc-e90a-4b7e-bb81-70c79d4c3846\"\ncompagnies:\n  2018: \"https://www.data.gouv.fr/fr/datasets/r/ddfea6a0-df7e-4402-99fc-165f573f2e10\"\n  2019: \"https://www.data.gouv.fr/fr/datasets/r/8421e029-c8c7-410d-b38c-54455ac3265d\"\n  2020: \"https://www.data.gouv.fr/fr/datasets/r/818eec10-6122-4788-8233-482e779ab837\"\n  2021: \"https://www.data.gouv.fr/fr/datasets/r/0b954774-ccd1-43ec-9b5a-f958fba03e87\"\n  2022: \"https://www.data.gouv.fr/fr/datasets/r/bcec3e1e-940a-4772-bc28-0d7b2b53c718\"\ngeojson:\n  airport: \"https://minio.lab.sspcloud.fr/projet-funathon/2024/sujet2/aeroports.geojson\""
  },
  {
    "objectID": "index.html#importer-la-liste-des-sources-disponibles",
    "href": "index.html#importer-la-liste-des-sources-disponibles",
    "title": "Un tableau de bord du trafic aérien avec  ou ",
    "section": "3.3 Importer la liste des sources disponibles",
    "text": "3.3 Importer la liste des sources disponibles\nLes consignes de cet exercice sont quasiment identiques selon le langage car les librairies R et Python pour lire des fichiers YAML portent le même nom.\n\n\n\n\n\n\n Exercice 1: lire les sources dans  et \n\n\n\n\n\n\nLe package R yaml comporte une fonction read_yaml pour transformer un fichier YAML en liste imbriquée; le package Python yaml comporte une fonction safe_load qui fait la même chose. Tester cette fonction sur le fichier sources.yml.\nTransformer ce bout de code en une fonction create_data_list prenant un argument source_file et renvoyant cette liste.\nCréer à la racine du projet un dossier R/ () ou src/ (). Attention, ne confondez pas avec le dossier correction/R/ ou correction/src/ qui contient la correction…\nDans ce nouveau dossier, créez un script nommé create_data_list.R () ou create_data_list.py () et reportez-y la fonction que vous avez créée. Dans le cas de Python, ce fichier doit commencer par import yaml, car ce package est utilisé dans la fonction.\n\n\n\n\n\n\n\n\n\n\nVoir la solution à cet exercice\n\n#' Creates a 2-levels list of urls, pointing to open source data\n#' \n#' @param source_file yaml file containing data urls \n#' @return list (level 1 = concepts, level 2 = year).\n#'\n#' @examples\n#'  create_data_list(\"sources.yml\")\n#'  \ncreate_data_list &lt;- function(source_file){\n  catalogue &lt;- yaml::read_yaml(source_file)\n  return(catalogue)\n}\n\nLa fonction-solution de cet exercice est dans le fichier correction/R/create_data_list.R. Elle peut être importée dans l’environnement global grâce à la commande:\n\nsource(\"correction/R/create_data_list.R\")\n\n\n\n\n\nVoir la solution à cet exercice\n\nimport yaml\n\ndef create_data_list(source_file):\n    \"\"\"\n    Reads a YAML file and returns the contents as a dictionary.\n\n    Args:\n        source_file (str): The path to the YAML file.\n\n    Returns:\n        dict: The contents of the YAML file.\n    \"\"\"\n    with open(source_file, 'r') as file:\n        catalogue = yaml.safe_load(file)\n    return catalogue\n\nLa fonction-solution de cet exercice est dans le fichier correction/src/create_data_list.py.\nUne fois que vous avez créé et rempli le fichier src/create_data_list.py, vous pouvez importer la fonction create_data_list dans l’environnement global grâce à la commande:\nfrom src.create_data_list import create_data_list\n\n\n\nCet exemple simple vous montre ce que sera l’organisation finale de l’application: l’application web qui sera construite plus tard dans les fichiers server.R et ui.R () ou app.py () pourra facilement appeler des fonctions utilitaires stockées dans R/ ou dans src/. Cette organisation est très pratique car elle sépare l’application web stricto sensu des fonctions génériques de manipulation de données et contribue à rendre les codes faciles à comprendre et à maintenir."
  },
  {
    "objectID": "index.html#importer-les-premières-bases",
    "href": "index.html#importer-les-premières-bases",
    "title": "Un tableau de bord du trafic aérien avec  ou ",
    "section": "3.4 Importer les premières bases",
    "text": "3.4 Importer les premières bases\nNous pouvons maintenant utiliser cette fonction pour lister tous nos URL des sources.\n\n\n\n\n\nurls &lt;- create_data_list(\"sources.yml\")\n\n\n\nurls = create_data_list(\"sources.yml\")\n\n\n\n\n\n\n\n\n\n Exercice 2: découvrir les différentes sources\n\n\n\n\n\nDans cet exercice, vous allez découvrir les sources utilisées dans le tutoriel et développer des fonctions génériques de traitement de données qui seront ensuite utilisées par l’application web.\n\nDonnées aéroports\n\nLes données sont des CSV européens (avec le séparateur ;). Il est donc conseillé d’utiliser la fonction read_csv2 du package readr pour lire les données à partir de la liste de fichiers unlist(urls$airports)4 si vous utilisez , et d’utiliser la fonction read_csv du package pandas pour lire les données à partir de la liste de fichiers list(urls['airports'].values()) si vous utilisez .\nIl est recommandé de ne pas laisser les types par défaut des colonnes mais de figer ceux-ci avec l’argument suivant:\n\n\n\n\n\ncol_types = cols(\n  ANMOIS = col_character(),\n  APT = col_character(),\n  APT_NOM = col_character(),\n  APT_ZON = col_character(),\n  .default = col_double()\n)\n\n\ndtype = {\n    \"ANMOIS\": \"str\",  \n    \"APT\": \"str\",     \n    \"APT_NOM\": \"str\", \n    \"APT_ZON\": \"str\",\n}\n\n\n\n\nA partir de la variable ANMOIS, créer les variables an et mois. Penser à enlever les 0 des mois de janvier à septembre.\n\n\n\nAide si vous êtes bloqué sur cette question\n\n\n\n\n\nPour extraire des éléments d’une chaine de caractère à partir de la position, il est recommandé d’utiliser la fonction str_sub du package stringr. Pour créer de nouvelles colonnes, il est recommandé d’utiliser la fonction mutate du package dplyr.\n\n\n\n\n\n\nConseil pour se faciliter la vie ultérieurement\n\n\n\nIl est recommandé d’utiliser str_remove pour retirer les zéros en début de mois qui pourront nous créer des difficultés ultérieurement.\n\n\nSi vous êtes toujours bloqué, la solution est donnée plus bas 👇\n\n\nVous pouvez utiliser les méthodes de données textuelles str.sub et str.replace de Pandas.\n\n\n\n\n\nCréer une fonction clean_dataframe qui prend en entrée un dataframe, crée les variables an et mois, ajoute une étape de passage des noms de colonne en minuscule et renvoie le dataframe en sortie.\n\n\n\nSolution\n\n\n\n\n\nclean_dataframe &lt;- function(df){\n  \n  # Create an et mois columns\n  df &lt;- df %&gt;% \n    mutate(\n      an = str_sub(ANMOIS,1,4),\n      mois = str_sub(ANMOIS,5,6)\n    ) %&gt;%\n    mutate(\n      mois = str_remove(mois, \"^0+\")\n    )\n  \n  # lower case for variable names\n  colnames(df) &lt;- tolower(colnames(df))\n  \n  return(df)\n\n}\n\n\ndef clean_dataframe(df):\n    # Create 'an' and 'mois' columns\n    df['an'] = df['ANMOIS'].astype(str).str[:4]\n    df['mois'] = df['ANMOIS'].astype(str).str[-2:]\n\n    # Remove leading zeros from 'mois' column\n    df['mois'] = df['mois'].str.replace(r'^0+', '', regex=True)\n\n    # Convert all column names to lowercase\n    df.columns = df.columns.str.lower()\n\n    return df\n\n\n\n\n\nCréer une fonction import_airport_data qui prend en input list_files et intègre les deux étapes précédentes: la lecture des données, le nettoyage avec clean_dataframe. Dans le cas de Python, ne pas oublier de concaténer les différentes tables avec pd.concat.\n\n\n\nSolution\n\n\n\n\n\nimport_airport_data &lt;- function(list_files){\n  \n  pax_apt_all &lt;- readr::read_csv2(\n    list_files, \n    col_types = cols(\n      ANMOIS = col_character(),\n      APT = col_character(),\n      APT_NOM = col_character(),\n      APT_ZON = col_character(),\n      .default = col_double()\n    )\n  ) %&gt;% \n    clean_dataframe()\n  \n  return(pax_apt_all)\n  \n}\n\nReporter cette fonction dans un fichier R/clean_dataframe.R et faire\n\nsource(\"R/clean_dataframe.R\")\n\n\nimport pandas as pd\nfrom .clean_dataframe import clean_dataframe\n\ndef import_airport_data(list_files):\n    # Define the data types for each column\n    col_types = {\n        \"ANMOIS\": \"str\",\n        \"APT\": \"str\",     # equivalent to col_character()\n        \"APT_NOM\": \"str\", # equivalent to col_character()\n        \"APT_ZON\": \"str\", # equivalent to col_character()\n    }\n\n    # Read the CSV file(s) with the specified column types\n    pax_apt_all = pd.concat([\n        pd.read_csv(file, delimiter = ';', dtype = col_types)\n        for file in list_files\n        ])\n\n    # Clean the DataFrame (assuming clean_dataframe is a predefined function)\n    pax_apt_all = clean_dataframe(pax_apt_all)\n\n    return pax_apt_all\n\nReporter cette fonction dans un fichier src/clean_dataframe.py et faire\n\nfrom src.clean_dataframe import clean_dataframe\n\n\n\n\n\n\nDonnées compagnies\nSur le même principe, créer une fonction import_compagnies_data qui effectue la même suite d’opérations. Faire néanmoins attention aux types des colonnes.\n\n\n\n\n\n\nRecommandation de paramètre pour read_csv2 pour l’import de ces fichiers\ncol_types = cols(\n  ANMOIS = col_character(),\n  CIE = col_character(),\n  CIE_NOM = col_character(),\n  CIE_NAT = col_character(),\n  CIE_PAYS = col_character(),\n  .default = col_double()\n)\n\n\n\n\nSolution\n\nimport_compagnies_data &lt;- function(list_files){\n  \n  pax_cie_all &lt;- readr::read_csv2(\n    file = list_files,\n    col_types = cols(\n      ANMOIS = col_character(),\n      CIE = col_character(),\n      CIE_NOM = col_character(),\n      CIE_NAT = col_character(),\n      CIE_PAYS = col_character(),\n      .default = col_double()\n    )\n  ) %&gt;% \n    clean_dataframe()\n  \n  return(pax_cie_all)\n  \n  \n}\n\n\n\nRecommandation de paramètre pour read_csv pour l’import de ces fichiers\ncol_types = {\n  ANMOIS = \"str\",\n  CIE = \"str\",\n  CIE_NOM = \"str\",\n  CIE_NAT = \"str\",\n  CIE_PAYS = \"str\"\n}\n\n\nSolution\n\ndef import_compagnies_data(list_files):\n    # Define the data types for each column\n    col_types = {\n        \"ANMOIS\": \"str\",\n        \"CIE\": \"str\",\n        \"CIE_NOM\": \"str\",\n        \"CIE_NAT\": \"str\",\n        \"CIE_PAYS\": \"str\"\n    }\n\n    # Read the CSV file(s) with the specified column types\n    pax_cie_all = pd.concat([\n        pd.read_csv(file, delimiter = ';', dtype = col_types)\n        for file in list_files\n        ])\n\n    # Clean the DataFrame (assuming clean_dataframe is a predefined function)\n    pax_cie_all = clean_dataframe(pax_cie_all)\n\n\n    return pax_cie_all\n\n\n\n\n\n\nDonnées liaisons\nSur le même principe, créer une fonction import_liaisons_data qui effectue la même suite d’opérations. Faire néanmoins attention aux types des colonnes.\n\n\n\n\n\n\nRecommandation de paramètre pour read_csv pour l’import de ces fichiers\ncol_types = cols(\n  ANMOIS = col_character(),\n  LSN = col_character(),\n  LSN_DEP_NOM = col_character(),\n  LSN_ARR_NOM = col_character(),\n  LSN_SCT = col_character(),\n  LSN_FSC = col_character(),\n  .default = col_double()\n)\n\n\n\n\nSolution\n\nimport_liaisons_data &lt;- function(list_files){\n  \n  pax_lsn_all &lt;- readr::read_csv2(\n    file = list_files,\n    col_types = cols(\n      ANMOIS = col_character(),\n      LSN = col_character(),\n      LSN_DEP_NOM = col_character(),\n      LSN_ARR_NOM = col_character(),\n      LSN_SCT = col_character(),\n      LSN_FSC = col_character(),\n      .default = col_double()\n    ) \n  ) %&gt;% \n    clean_dataframe()\n  \n  return(pax_lsn_all)\n  \n  \n}\n\n\n\nConseil pour les colonnes:\ncol_types = {\n  \"ANMOIS\": \"str\",\n  \"LSN\": \"str\",\n  \"LSN_DEP_NOM\": \"str\",\n  \"LSN_ARR_NOM\": \"str\",\n  \"LSN_SCT\": \"str\",\n  \"LSN_FSC\": \"str\"\n}\n\n\nSolution\n\ndef import_liaisons_data(list_files):\n    # Define the data types for each column\n    col_types = {\n        \"ANMOIS\": \"str\",\n        \"LSN\": \"str\",\n        \"LSN_DEP_NOM\": \"str\",\n        \"LSN_ARR_NOM\": \"str\",\n        \"LSN_SCT\": \"str\",\n        \"LSN_FSC\": \"str\"\n    }\n\n    # Read the CSV file(s) with the specified column types\n    pax_lsn_all = pd.concat([\n        pd.read_csv(file, delimiter = ';', dtype = col_types)\n        for file in list_files\n        ])\n\n    # Clean the DataFrame\n    pax_lsn_all = clean_dataframe(pax_lsn_all)\n\n    return pax_lsn_all\n\n\n\n\n\n\nConstruction de fichiers de fonctions\n\nReporter la fonction clean_dataframe dans un fichier R/clean_dataframe.R () ou topinambour/clean_dataframe.py ().\nReporter les fonctions import_airport_data, import_compagnies_data et import_liaisons_data dans un fichier R/import_data.R () ou scr/import_data.py (). Dans le cas de Python, le fichier devra commencer par ceci:\n\nimport pandas as pd\nfrom .clean_dataframe import clean_dataframe\n\n\n\n\nA l’issue de cette partie, vous devriez avoir le fichier R/import_data.R suivant\n\n\nLe fichier R/import_data.R attendu\n\n\n\nR/import_data.R\n\nimport_airport_data &lt;- function(list_files){\n  \n  pax_apt_all &lt;- readr::read_csv2(\n    list_files, \n    col_types = cols(\n      ANMOIS = col_character(),\n      APT = col_character(),\n      APT_NOM = col_character(),\n      APT_ZON = col_character(),\n      .default = col_double()\n    )\n  ) %&gt;% \n    clean_dataframe()\n  \n  return(pax_apt_all)\n  \n}\n\n\nimport_compagnies_data &lt;- function(list_files){\n  \n  pax_cie_all &lt;- readr::read_csv2(\n    file = list_files,\n    col_types = cols(\n      ANMOIS = col_character(),\n      CIE = col_character(),\n      CIE_NOM = col_character(),\n      CIE_NAT = col_character(),\n      CIE_PAYS = col_character(),\n      .default = col_double()\n    )\n  ) %&gt;% \n    clean_dataframe()\n  \n  return(pax_cie_all)\n  \n  \n}\n\n\nimport_liaisons_data &lt;- function(list_files){\n  \n  pax_lsn_all &lt;- readr::read_csv2(\n    file = list_files,\n    col_types = cols(\n      ANMOIS = col_character(),\n      LSN = col_character(),\n      LSN_DEP_NOM = col_character(),\n      LSN_ARR_NOM = col_character(),\n      LSN_SCT = col_character(),\n      LSN_FSC = col_character(),\n      .default = col_double()\n    ) \n  ) %&gt;% \n    clean_dataframe()\n  \n  return(pax_lsn_all)\n  \n  \n}\n\n\n\n\nA l’issue de cette partie, vous devriez avoir le fichier src/import_data.py suivant\n\n\nLe fichier src/import_data.py attendu\n\n\n\nsrc/import_data.py\n\nimport pandas as pd\nfrom .clean_dataframe import clean_dataframe\n\ndef import_airport_data(list_files):\n    # Define the data types for each column\n    col_types = {\n        \"ANMOIS\": \"str\",\n        \"APT\": \"str\",     # equivalent to col_character()\n        \"APT_NOM\": \"str\", # equivalent to col_character()\n        \"APT_ZON\": \"str\", # equivalent to col_character()\n    }\n\n    # Read the CSV file(s) with the specified column types\n    pax_apt_all = pd.concat([\n        pd.read_csv(file, delimiter = ';', dtype = col_types)\n        for file in list_files\n        ])\n\n    # Clean the DataFrame (assuming clean_dataframe is a predefined function)\n    pax_apt_all = clean_dataframe(pax_apt_all)\n\n    return pax_apt_all\n\n\n\ndef import_compagnies_data(list_files):\n    # Define the data types for each column\n    col_types = {\n        \"ANMOIS\": \"str\",\n        \"CIE\": \"str\",\n        \"CIE_NOM\": \"str\",\n        \"CIE_NAT\": \"str\",\n        \"CIE_PAYS\": \"str\"\n    }\n\n    # Read the CSV file(s) with the specified column types\n    pax_cie_all = pd.concat([\n        pd.read_csv(file, delimiter = ';', dtype = col_types)\n        for file in list_files\n        ])\n\n    # Clean the DataFrame (assuming clean_dataframe is a predefined function)\n    pax_cie_all = clean_dataframe(pax_cie_all)\n\n\n    return pax_cie_all\n\n\ndef import_liaisons_data(list_files):\n    # Define the data types for each column\n    col_types = {\n        \"ANMOIS\": \"str\",\n        \"LSN\": \"str\",\n        \"LSN_DEP_NOM\": \"str\",\n        \"LSN_ARR_NOM\": \"str\",\n        \"LSN_SCT\": \"str\",\n        \"LSN_FSC\": \"str\"\n    }\n\n    # Read the CSV file(s) with the specified column types\n    pax_lsn_all = pd.concat([\n        pd.read_csv(file, delimiter = ';', dtype = col_types)\n        for file in list_files\n        ])\n\n    # Clean the DataFrame\n    pax_lsn_all = clean_dataframe(pax_lsn_all)\n\n    return pax_lsn_all\n\n\n\n\n\n\n\nLocalisations des aéroports\nIl s’agit d’un jeu de données spatial. Pour en savoir plus sur ce type de données, il est recommandé de consulter :\n\nPour les utilisateurs de : la fiche utilitR sur le sujet ou ce cours introductif.\nPour les utilisateurs de : ce chapitre du cours de Python de l’ENSAE.\n\n\n\n\n\n\nUtiliser la fonction st_read du package sf pour lire ces données (dont la localisation est stockée dans la variable urls$geojson$airport). Stocker l’objet obtenu sous le nom airports_location\n\n\n\n\nUtiliser la fonction read_file du package geopandas pour lire ces données (dont la localisation est stockée dans la variable urls['geojson']['airport']). Stocker l’objet obtenu sous le nom airports_location\n\n\n\n\n\nVérifier que les données sont bien dans le système de représentation WGS 845\n\n\n\nAide\n\nLa fonction à utiliser est st_crs  ou l’attribut crs pour \n\n\nIl est toujours utile de vérifier que nos données sont bien localisées où on les attend. Pour cela, il est pertinent de faire une carte avec un fond de carte contextuel, même si celle-ci n’est pas très soignée. Pour faire ceci, le plus simple est d’utiliser la librairie Javascript Leaflet. L’usage n’est pas exactement le même en R et en Python:\n\n\nla fonction addMarkers du package leaflet ();\nles fonctions Map et add_to du package folium ().\n\nEssayez de faire cette carte vous-mêmes ou consultez l’aide ci-dessous\n\n\nCode pour faire une carte leaflet minimale\n\n# En R\nleaflet(airports_location) %&gt;%\n  addTiles() %&gt;%\n  addMarkers(popup = ~Nom)\n# En Python\nimport folium \nm = folium.Map()\n\nfolium.GeoJson(airports_location).add_to(m)\nm\n\n\n\n\n\nLa carte leaflet que vous devriez avoir obtenue à la fin de l’exercice est la suivante:\n\nleaflet(airports_location) %&gt;%\n  addTiles() %&gt;%\n  addMarkers(popup = ~Nom)\n\n\n\n\n\n\n\n\n\nA l’issue de l’exercice, le code centralisé dans le script R/import_data.R peut être importé via le code suivant\n\nsource(\"R/import_data.R\")\n\nVous pouvez initier un script nommé main.R avec les lignes suivante:\n\n\nmain.R\n\nMONTHS_LIST = 1:12\n\n# Load data ----------------------------------\nurls &lt;- create_data_list(\"./sources.yml\")\n\n\npax_apt_all &lt;- import_airport_data(unlist(urls$airports))\npax_cie_all &lt;- import_compagnies_data(unlist(urls$compagnies))\npax_lsn_all &lt;- import_liaisons_data(unlist(urls$liaisons))\n\nairports_location &lt;- st_read(urls$geojson$airport)\n\nen les faisant précéder de l’import des scripts que nous avons déjà créés dans le dossier R:\nsource(\"R/create_data_list.R\")\nsource(\"R/import_data.R\")  \nsource(\"R/clean_dataframe.R\")\nUne bonne pratique est de tester son script dans une session vierge. Cela amène à construire pas à pas une chaine plus reproductible. Pour cela,\n\nAller dans les options de  via Tools &gt; Global Options et décocher la case Restore .RData into workspace at setup\nRedémarrer votre session  via le menu Session &gt; Restart R ou le raccourci CTRL+SHIFT+F10\nExécuter votre fichier main.R. Vous devriez rencontrer des erreurs car nous n’avons pas géré les import de librairies dans ce script puisque notre session actuelle ne bénéficie plus des import antérieurs.\n\nUne bonne pratique pour comprendre cette exigence de reproductibilité est d’itérativement ajouter les librairies utiles à mesure qu’on rencontre des erreurs (notre code étant très rapide à tourner, cette logique d’essai-erreur n’est pas très coûteuse). Si vous ne désirez pas faire ceci (dommage, c’est un bon exercice), vous pouvez trouver les imports de packages à faire pour que notre script soit reproductible.\n\n\nL’environnement minimal de reproductibilité pour que le script main.R fonctionne\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(sf)\n\nCes librairies sont à écrire au début de main.R.\n\n\nA l’issue de l’exercice, le code centralisé dans le script src/import_data.py peut être importé via le code suivant\nimport src.import_data as sid"
  },
  {
    "objectID": "index.html#objectifs-1",
    "href": "index.html#objectifs-1",
    "title": "Un tableau de bord du trafic aérien avec  ou ",
    "section": "4.1 Objectifs",
    "text": "4.1 Objectifs\nDans cette partie, vous allez exploiter les données pour produire trois valorisations qui seront ensuite intégrées dans l’application web:\n\nun graphique dynamique présentant le trafic pour un aéroport donné;\nun tableau HTML affichant des données sur le trafic;\nune carte des aéroports.\n\nUne fois que ces valorisations seront prêtes, nous pourrons nous pencher sur leur intégration dans une application interactive."
  },
  {
    "objectID": "index.html#prérequis-créer-le-script-main",
    "href": "index.html#prérequis-créer-le-script-main",
    "title": "Un tableau de bord du trafic aérien avec  ou ",
    "section": "4.2 Prérequis: créer le script main",
    "text": "4.2 Prérequis: créer le script main\nPour commencer, vous allez créer un fichier fichier main.R () ou main.py () à la racine du dépôt. Ensuite, vous pouvez y copier le code suivant.\n\n\n\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(sf)\nlibrary(plotly)\n\nsource(\"correction/R/import_data.R\")\nsource(\"correction/R/create_data_list.R\")\nsource(\"correction/R/clean_dataframe.R\")\nsource(\"correction/R/figures.R\")\n\n\n# Load data ----------------------------------\nurls &lt;- create_data_list(\"./sources.yml\")\n\n\npax_apt_all &lt;- import_airport_data(unlist(urls$airports))\npax_cie_all &lt;- import_compagnies_data(unlist(urls$compagnies))\npax_lsn_all &lt;- import_liaisons_data(unlist(urls$liaisons))\n\nairports_location &lt;- st_read(urls$geojson$airport)\n\nliste_aeroports &lt;- unique(pax_apt_all$apt)\ndefault_airport &lt;- liste_aeroports[1]\n\n\nimport pandas as pd\nimport geopandas as gpd\nimport plotly.express as px\nfrom plotnine import ggplot, geom_line, aes\n\nimport src.import_data as sid\nfrom src.create_data_list import create_data_list\n\n# Load data ----------------------------------\nurls = create_data_list(\"./sources.yml\")\n\n\npax_apt_all = sid.import_airport_data(urls['airports'].values())\npax_cie_all = sid.import_airport_data(urls['compagnies'].values())\npax_lsn_all = sid.import_airport_data(urls['liaisons'].values())\n\n\nairports_location = gpd.read_file(\n    urls['geojson']['airport']\n)\n\n\nliste_aeroports = pax_apt_all['apt'].unique()\ndefault_airport = liste_aeroports[0]"
  },
  {
    "objectID": "index.html#valorisation-1-le-trafic-par-aéroport",
    "href": "index.html#valorisation-1-le-trafic-par-aéroport",
    "title": "Un tableau de bord du trafic aérien avec  ou ",
    "section": "4.3 Valorisation 1: Le trafic par aéroport",
    "text": "4.3 Valorisation 1: Le trafic par aéroport\nLa première valorisation qui sera intégrée dans l’application web est un graphique décrivant le trafic aérien au niveau d’un aéroport. Nous allon d’abord créer une figure minimale (avec ggplot  ou son équivalent  plotnine) pour vérifier que nos données ont bien la dimension temporelle attendue. Cependant, comme Shiny est un système interactif, nous allons ensuite utiliser la librairie Plotly pour faire des figures dynamiques: il s’agit d’une librairie Javascript qui peut être appelée grâce à des librairies clientes en  ou .\n\n\n\n\n\n\n Exercice 3: Produire un graphique de fréquentation des aéroports\n\n\n\n\n\nDans le script main.R ou main.py:\n\nCréer une variable trafic égale apt_pax_dep + apt_pax_tr + apt_pax_arr;\nNe conserver que les données relatives à l’aéroport default_airport;\nCréer une variable date qui utilise les colonnes an et mois. Cette variable de date doit être au format date, pas au format chr.\n\n\n\nEnchaînement des opérations attendues à cette étape\n\n\n\n\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(sf)\nlibrary(plotly)\n\nsource(\"correction/R/import_data.R\")\nsource(\"correction/R/create_data_list.R\")\nsource(\"correction/R/clean_dataframe.R\")\nsource(\"correction/R/figures.R\")\n\n\n# Load data ----------------------------------\nurls &lt;- create_data_list(\"./sources.yml\")\n\n\npax_apt_all &lt;- import_airport_data(unlist(urls$airports))\npax_cie_all &lt;- import_compagnies_data(unlist(urls$compagnies))\npax_lsn_all &lt;- import_liaisons_data(unlist(urls$liaisons))\n\nairports_location &lt;- st_read(urls$geojson$airport)\n\nliste_aeroports &lt;- unique(pax_apt_all$apt)\ndefault_airport &lt;- liste_aeroports[1]\n\n\ntrafic_aeroports &lt;- pax_apt_all %&gt;%\n  mutate(trafic = apt_pax_dep + apt_pax_tr + apt_pax_arr) %&gt;%\n  filter(apt %in% default_airport) %&gt;%\n  mutate(\n    date = as.Date(paste(anmois, \"01\", sep=\"\"), format = \"%Y%m%d\")\n  )\n\n\nimport pandas as pd\nimport geopandas as gpd\nimport plotly.express as px\nfrom plotnine import ggplot, geom_line, aes\n\nimport src.import_data as sid\nfrom src.create_data_list import create_data_list\n\n# Load data ----------------------------------\nurls = create_data_list(\"./sources.yml\")\n\n\npax_apt_all = sid.import_airport_data(urls['airports'].values())\npax_cie_all = sid.import_airport_data(urls['compagnies'].values())\npax_lsn_all = sid.import_airport_data(urls['liaisons'].values())\n\n\nairports_location = gpd.read_file(\n    urls['geojson']['airport']\n)\n\n\nliste_aeroports = pax_apt_all['apt'].unique()\ndefault_airport = liste_aeroports[0]\n\n\npax_apt_all['trafic'] = pax_apt_all['apt_pax_dep'] + \\\n  pax_apt_all['apt_pax_tr'] + \\\n  pax_apt_all['apt_pax_arr']\n\ntrafic_aeroports = (\n  pax_apt_all\n  .loc[pax_apt_all['apt'] == default_airport]\n)\ntrafic_aeroports['date'] = pd.to_datetime(\n  trafic_aeroports['anmois'] + '01', format='%Y%m%d'\n)\n\n\n\n\n\nFaire une figure statique pour observer la dynamique des données:\n\n\nPour les utilisateurs de , ce sera bien sûr avec ggplot ;\nPour les utilisateurs de , vous pouvez utiliser le module graphique de votre choix: matplotlib, seaborn ou plotnine. Nous recommandons néanmoins plotnine, la transposition en  de la grammaire des graphiques ggplot.\n\nVous devriez obtenir une figure similaire à celle-ci:\n\n\n\n\n\nIl est inutile d’aller plus loin sur la mise en forme de cette figure, car l’application interactive comportera in fine des figures dynamiques (qui se modifient en fonction des demandes de l’utilisateur) plutôt que des figures statiques comme celle que vous venez de produire.\n\nNous allons maintenant faire une figure dynamique avec la librairie Plotly. Pour cela, vous pouvez vous inspirer de cette page () ou celle-ci (). La figure que vous devriez avoir est la suivante:\n\n\n\n\n\n\n\n\n\nAide: le code pour générer la figure\n\n\n\n\n\nfigure_ggplot &lt;- trafic_aeroports %&gt;%\n  ggplot(.) + geom_line(aes(x = date, y = trafic))\n\nfigure_plotly &lt;- plot_airport_line(trafic_aeroports, default_airport)\n\n\nfigure_plotly = px.line(\n  trafic_aeroports, x=\"date\", y=\"trafic\",\n  text=\"apt_nom\"\n)\n\nfigure_plotly.update_traces(\n  mode=\"markers+lines\", type = \"scatter\",\n  hovertemplate=\"&lt;i&gt;Aéroport:&lt;/i&gt; %{text}&lt;br&gt;Trafic: %{y}\"\n)\n\n\n\n\n\n\n\nLe code complet pour répliquer cet exercice est donné ci-dessous.\n\n\nCode de l’exercice\n\n\n\n\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(sf)\nlibrary(plotly)\n\nsource(\"correction/R/import_data.R\")\nsource(\"correction/R/create_data_list.R\")\nsource(\"correction/R/clean_dataframe.R\")\nsource(\"correction/R/figures.R\")\n\n\n# Load data ----------------------------------\nurls &lt;- create_data_list(\"./sources.yml\")\n\n\npax_apt_all &lt;- import_airport_data(unlist(urls$airports))\npax_cie_all &lt;- import_compagnies_data(unlist(urls$compagnies))\npax_lsn_all &lt;- import_liaisons_data(unlist(urls$liaisons))\n\nairports_location &lt;- st_read(urls$geojson$airport)\n\nliste_aeroports &lt;- unique(pax_apt_all$apt)\ndefault_airport &lt;- liste_aeroports[1]\n\n\ntrafic_aeroports &lt;- pax_apt_all %&gt;%\n  mutate(trafic = apt_pax_dep + apt_pax_tr + apt_pax_arr) %&gt;%\n  filter(apt %in% default_airport) %&gt;%\n  mutate(\n    date = as.Date(paste(anmois, \"01\", sep=\"\"), format = \"%Y%m%d\")\n  )\n\n\n# VALORISATIONS ----------------------------------------------\n\nfigure_ggplot &lt;- trafic_aeroports %&gt;%\n  ggplot(.) + geom_line(aes(x = date, y = trafic))\n\nfigure_plotly &lt;- plot_airport_line(trafic_aeroports, default_airport)\n\n\nimport pandas as pd\nimport geopandas as gpd\nimport plotly.express as px\nfrom plotnine import ggplot, geom_line, aes\n\nimport src.import_data as sid\nfrom src.create_data_list import create_data_list\n\n# Load data ----------------------------------\nurls = create_data_list(\"./sources.yml\")\n\n\npax_apt_all = sid.import_airport_data(urls['airports'].values())\npax_cie_all = sid.import_airport_data(urls['compagnies'].values())\npax_lsn_all = sid.import_airport_data(urls['liaisons'].values())\n\n\nairports_location = gpd.read_file(\n    urls['geojson']['airport']\n)\n\n\nliste_aeroports = pax_apt_all['apt'].unique()\ndefault_airport = liste_aeroports[0]\n\n\npax_apt_all['trafic'] = pax_apt_all['apt_pax_dep'] + \\\n  pax_apt_all['apt_pax_tr'] + \\\n  pax_apt_all['apt_pax_arr']\n\ntrafic_aeroports = (\n  pax_apt_all\n  .loc[pax_apt_all['apt'] == default_airport]\n)\ntrafic_aeroports['date'] = pd.to_datetime(\n  trafic_aeroports['anmois'] + '01', format='%Y%m%d'\n)\n\n\n# VALORISATIONS ----------------------------------------------\n\nfigure_ggplot = (\n    ggplot(trafic_aeroports) +\n    geom_line(aes(x = \"date\", y = \"trafic\"))\n)\n\n\nfigure_plotly = px.line(\n  trafic_aeroports, x=\"date\", y=\"trafic\",\n  text=\"apt_nom\"\n)\n\nfigure_plotly.update_traces(\n  mode=\"markers+lines\", type = \"scatter\",\n  hovertemplate=\"&lt;i&gt;Aéroport:&lt;/i&gt; %{text}&lt;br&gt;Trafic: %{y}\"\n)\n\n\n\n\nNous proposons de le transformer en fonction, ce sera plus simple à intégrer ultérieurement dans notre application\n\n\n\n\n\n\n Exercice 3b: une fonction de production graphique\n\n\n\n\n\nTransformer le code ci-dessus en une fonction nommée plot_airport_line afin que:\n\nles inputs soient les suivants: un dataframe et un aéroport à sélectionner;\nla sortie soit notre figure plotly.\n\nTester la fonction sur d’autres aéroports de la liste. Quand vous êtes satisfaits de celle-ci, déplacer la définition de cette fonction dans R/figures.R () ou src/figures.py (). Dans le cas de Python, le fichier devra commencer par ceci:\nimport pandas as pd\nimport plotly.express as px\n\n\n\n\n\n\n\n\n\nFichier R/figures.R à l’issue de cet exercice\n\n\n\nR/figures.R\n\n\nplot_airport_line &lt;- function(df, selected_airport){\n  trafic_aeroports &lt;- df %&gt;%\n    mutate(trafic = apt_pax_dep + apt_pax_tr + apt_pax_arr) %&gt;%\n    filter(apt %in% selected_airport) %&gt;%\n    mutate(\n      date = as.Date(paste(anmois, \"01\", sep=\"\"), format = \"%Y%m%d\")\n    )\n  \n  figure_plotly &lt;- trafic_aeroports %&gt;%\n    plot_ly(\n      x = ~date, y = ~trafic,\n      text = ~apt_nom,\n      hovertemplate = paste(\"&lt;i&gt;Aéroport:&lt;/i&gt; %{text}&lt;br&gt;Trafic: %{y}\") ,\n      type = 'scatter', mode = 'lines+markers')\n  \n  return(figure_plotly)\n}\n\n\nPar la suite, nous pouvons ajouter la ligne suivante au début de notre fichier main.R:\n\nsource(\"R/figures.R\")\n\net utiliser cette fonction à la fin du fichier.\n\n\nPar la suite, nous pouvons ajouter la ligne suivante au début de notre fichier main.py:\nfrom src.figures import plot_airport_line\net utiliser cette fonction à la fin du fichier.\n\n\nFichier main.py à l’issue de cet exercice\n\n\n\nmain.py\n\nimport pandas as pd\nimport geopandas as gpd\nimport plotly.express as px\nfrom plotnine import ggplot, geom_line, aes\n\nimport src.import_data as sid\nfrom src.create_data_list import create_data_list\n\n# Load data ----------------------------------\nurls = create_data_list(\"./sources.yml\")\n\n\npax_apt_all = sid.import_airport_data(urls['airports'].values())\npax_cie_all = sid.import_airport_data(urls['compagnies'].values())\npax_lsn_all = sid.import_airport_data(urls['liaisons'].values())\n\n\nairports_location = gpd.read_file(\n    urls['geojson']['airport']\n)\n\n\nliste_aeroports = pax_apt_all['apt'].unique()\ndefault_airport = liste_aeroports[0]\n\n\n# OBJETS NECESSAIRES A L'APPLICATION ------------------------\n\npax_apt_all['trafic'] = pax_apt_all['apt_pax_dep'] + \\\n  pax_apt_all['apt_pax_tr'] + \\\n  pax_apt_all['apt_pax_arr']\n\ntrafic_aeroports = (\n  pax_apt_all\n  .loc[pax_apt_all['apt'] == default_airport]\n)\ntrafic_aeroports['date'] = pd.to_datetime(\n  trafic_aeroports['anmois'] + '01', format='%Y%m%d'\n)\n\n\n# VALORISATIONS ----------------------------------------------\n\nfrom src.figures import plot_airport_line\n\nfigure_plotly = plot_airport_line(trafic_aeroports, default_airport)"
  },
  {
    "objectID": "index.html#valorisation-2-tableau-html-pour-afficher-des-données",
    "href": "index.html#valorisation-2-tableau-html-pour-afficher-des-données",
    "title": "Un tableau de bord du trafic aérien avec  ou ",
    "section": "4.4 Valorisation 2: Tableau HTML pour afficher des données",
    "text": "4.4 Valorisation 2: Tableau HTML pour afficher des données\nLa deuxième valorisation qui sera intégrée dans l’application web est un tableau permettant de visualiser certaines données directement dans le dashboard. Il existe plusieurs packages pour faire cela, que ce soit en  ou .\nL’écosystème le plus complet pour construire ce tableau est développé par Posit et est quasi équivalent qu’on fasse du  ou du  (il est plus complet en  car plus ancien dans ce langage). Il s’agit du package GT () ou Great Tables (). En peu de temps, ces packages sont devenus incontournables et proposent des fonctionnalités bien plus complètes que les solutions qui existaient par le passé, notamment DT.\nPour le prochain exercice, vous pourrez utiliser les objets suivants. Copiez-les à la fin de votre script main.\n\n\n\n\n\nYEARS_LIST  &lt;- as.character(2018:2022)\nMONTHS_LIST &lt;- 1:12\n\n\n\nYEARS_LIST = [str(year) for year in range(2018, 2023)]\nMONTHS_LIST = list(range(1, 13))\n\n\n\n\n\n\n\n\n\n Exercice 4a: préparer les données avant de faire un beau tableau\n\n\n\n\n\nNous allons intégrer dans notre application deux tableaux de statistiques descriptives.\n\nChoisir un mois et une année à partir des objets YEARS_LIST et MONTHS_LIST pour faire un filtre sur le dataframe pax_apt_all. Une fois que vous êtes satisfaits, transformer cela en une fonction create_data_from_input prenant en argument un dataframe, une année et un mois, et renvoyant un dataframe.\n\n\n\n\n\n\n\nCode de l’exercice\n\ncreate_data_from_input &lt;- function(data, year, month){\n  data &lt;- data %&gt;%\n    filter(mois %in% month, an %in% year)\n  return(data)\n}\n\n\n\n\n\n\nCode de l’exercice\n\nimport pandas as pd\n\ndef create_data_from_input(data, year, month):\n  data = (\n    data\n\n\n\n\n\nPour chaque aéroport (défini par son nom et par son code), calculer le nombre total de passagers au départ, à l’arrivée, en transit, et total, puis classer les aéroports du plus fréquenté au moins fréquenté (en nombre total de passagers). Stocker le résultat dans l’objet stats_aeroports. Une fois que vous êtes satisfaits de votre chaine d’opération, créer une fonction summary_stat_airport qui prend en entrée un dataframe et renvoie un dataframe.\n\n\n\n\n\n\n\nCode de l’exercice\n\n  table2 &lt;- data %&gt;%\n    group_by(apt, apt_nom) %&gt;%\n    summarise(\n      paxdep = round(sum(apt_pax_dep, na.rm = T),3),\n      paxarr = round(sum(apt_pax_arr, na.rm = T),3),\n      paxtra = round(sum(apt_pax_tr, na.rm = T),3)) %&gt;%\n    arrange(desc(paxdep)) %&gt;%\n    ungroup()\n  \n  return(table2)\n}\n\nsummary_stat_liaisons &lt;- function(data){\n  agg_data &lt;- data %&gt;%\n    group_by(lsn_fsc) %&gt;%\n    summarise(\n      paxloc = round(sum(lsn_pax_loc, na.rm = TRUE)*1e-6,3)\n    ) %&gt;%\n    ungroup()\n  return(agg_data)\n}\n\n\n\n\n\n\nCode de l’exercice\n\n    ]\n  )\n  return data\n\n\ndef summary_stat_airport(data):\n    table2 = (\n        data\n        .groupby([\"apt\", \"apt_nom\"])\n        .agg({\"apt_pax_dep\": \"sum\", \"apt_pax_arr\": \"sum\", \"apt_pax_tr\": \"sum\", \"trafic\": \"sum\"})\n        .sort_values(\"trafic\", ascending=False)\n        .reset_index()\n    )\n    table2.columns = table2.columns.str.replace(\"apt_pax_\", \"pax\")\n    return table2\n\n\n\n\n\nReporter les fonctions créées dans cet exercice dans un script R/divers_functions.R () ou src/divers_functions.py (). Dans le cas de Python, ce fichier doit commencer par import pandas as pd, car ce package est utilisé dans la fonction.\nEnrichir le script main.R (resp. main.py) pour utiliser celles-ci en créant les dataframes adéquats (correction ci-dessous).\n\n\n\n\nVoici une proposition de script main.R (resp. main.py) à l’issue de cet exercice\n\n\n\n\n\n\nCode de l’exercice\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(leaflet)\n\nsource(\"correction/R/import_data.R\")\nsource(\"correction/R/create_data_list.R\")\nsource(\"correction/R/clean_dataframe.R\")\nsource(\"correction/R/divers_functions.R\")\nsource(\"correction/R/figures.R\")\n\nYEARS_LIST  &lt;- as.character(2018:2022)\nMONTHS_LIST &lt;- 1:12\nyear &lt;- YEARS_LIST[1]\nmonth &lt;- MONTHS_LIST[1]\n\n\n# Load data ----------------------------------\nurls &lt;- create_data_list(\"./sources.yml\")\n\n\npax_apt_all &lt;- import_airport_data(unlist(urls$airports))\npax_cie_all &lt;- import_compagnies_data(unlist(urls$compagnies))\npax_lsn_all &lt;- import_liaisons_data(unlist(urls$liaisons))\n\nairports_location &lt;- st_read(urls$geojson$airport)\n\nliste_aeroports &lt;- unique(pax_apt_all$apt)\ndefault_airport &lt;- liste_aeroports[1]\n\n# OBJETS NECESSAIRES A L'APPLICATION ------------------------\n\ntrafic_aeroports &lt;- pax_apt_all %&gt;%\n  mutate(trafic = apt_pax_dep + apt_pax_tr + apt_pax_arr) %&gt;%\n  filter(apt %in% default_airport) %&gt;%\n  mutate(\n    date = as.Date(paste(anmois, \"01\", sep=\"\"), format = \"%Y%m%d\")\n  )\n\nstats_aeroports &lt;- summary_stat_airport(\n  create_data_from_input(pax_apt_all, year, month)\n)\n\n\n\n# VALORISATIONS ----------------------------------------------\n\nfigure_plotly &lt;- plot_airport_line(trafic_aeroports,default_airport)\n\n\n\n\n\n\nCode de l’exercice\n\nimport pandas as pd\nimport geopandas as gpd\nimport plotly.express as px\nfrom plotnine import ggplot, geom_line, aes\n\nimport src.import_data as sid\nfrom src.create_data_list import create_data_list\nfrom src.divers_functions import (\n  create_data_from_input,\n  summary_stat_airport\n)\n\nYEARS_LIST = [str(year) for year in range(2018, 2023)]\nMONTHS_LIST = list(range(1, 13))\nyear = YEARS_LIST[0]\nmonth = MONTHS_LIST[0]\n\n# Load data ----------------------------------\nurls = create_data_list(\"./sources.yml\")\n\n\npax_apt_all = sid.import_airport_data(urls['airports'].values())\npax_cie_all = sid.import_airport_data(urls['compagnies'].values())\npax_lsn_all = sid.import_airport_data(urls['liaisons'].values())\n\n\nairports_location = gpd.read_file(\n    urls['geojson']['airport']\n)\n\n\nliste_aeroports = pax_apt_all['apt'].unique()\ndefault_airport = liste_aeroports[0]\n\n\n# OBJETS NECESSAIRES A L'APPLICATION ------------------------\n\npax_apt_all['trafic'] = pax_apt_all['apt_pax_dep'] + \\\n  pax_apt_all['apt_pax_tr'] + \\\n  pax_apt_all['apt_pax_arr']\n\ntrafic_aeroports = (\n  pax_apt_all\n  .loc[pax_apt_all['apt'] == default_airport]\n)\ntrafic_aeroports['date'] = pd.to_datetime(\n  trafic_aeroports['anmois'] + '01', format='%Y%m%d'\n)\n\n\n# VALORISATIONS ----------------------------------------------\n\nfrom src.figures import plot_airport_line\n\nfigure_plotly = plot_airport_line(trafic_aeroports, default_airport)\n\n\n\n\nNous avons maintenant tous les ingrédients pour faire un tableau de statistiques descriptives lisibles et esthétiques. Avant de créer cette table, nous allons créer une colonne supplémentaire:\n\n\n\n\n\nstats_aeroports_table &lt;- stats_aeroports %&gt;%\n  mutate(name_clean = paste0(str_to_sentence(apt_nom), \" _(\", apt, \")_\")\n) %&gt;%\nselect(name_clean, everything())\n\n\n\nstats_aeroports['name_clean'] = stats_aeroports['apt_nom'].str.title() + \" _(\" + stats_aeroports['apt'] + \")_\"\nstats_aeroports = stats_aeroports[ ['name_clean'] + [ col for col in stats_aeroports.columns if col != 'name_clean' ] ]\n\n\n\nCelle-ci nous permettra, une fois mise en forme, d’avoir une colonne plus esthétique.\n\n\n\n\n\n\n Exercice 4b: un beau tableau (enfin !)\n\n\n\n\n\nLes différentes questions vont permettre de construire et formatter progressivement notre tableau. Si vous êtes bloqués, les réponses sont ci-dessous dans des menus déroulants.\n\nEn premier lieu, utiliser GT pour faire un tableau basique sur le dataframe stats_aeroports (pour les utilisateurs de , le faire sur stats_aeroports.head(15) car il n’est pas encore possible de limiter la taille de la page). N’utiliser aucune option, celles-ci vont être progressivement ajoutées.\nRetirer les colonnes apt et apt_nom de notre table.\n\n\nIl y a plusieurs manières de faire, voici un indice sur la “meilleure”\n\n\nEn , il est possible d’utiliser des fonctions de sélection de colonnes issues du tidyverse dans GT, notamment la fonction starts_with (à ne pas confondre avec celle de stringr)\nEn , quand on fournit un DataFrame Polars, on peut utiliser les fonctions de sélection qui ressemblent à celles du tidyverse. Néanmoins, là nous avons un DataFrame Pandas. Il faudra donc utiliser des méthodes Pandas, un peu plus verbeuses, du type\n\n stats_aeroports.filter(like = \"&lt;debut_de_string&gt;\").columns.tolist()\n\nFormatter les colonnes numériques (pour la sélection des colonnes numériques, voir l’indice ci-dessus). En consultant la documentation de gt, appliquer l’option qui permet de rendre plus concise la notation des milliers (K) et millions (M).\nUtiliser fmt_markdown pour appliquer une mise en forme adaptée à la colonne name_clean\nMettre en forme les noms de colonne (cols_label), le titre (tab_header), les notes (tab_source_note) pour avoir un tableau esthéthique et informatif. Pour les utilisateurs de , vous pouvez aussi modifier la couleur de la partie supérieure du tableau (tab_style).\nPour les utilisateurs de , transformer la table en tableau interactif avec opt_interactive6.\n\n\n\n\nLes réponses aux différentes questions sont données de manière successives ci-dessous. La table finale, obtenue à l’issue de l’exercice est la suivante:\n\n\n\n\n\n\nRéponse question 1\nlibrary(gt)\ntable_aeroports &lt;- gt(stats_aeroports_table)\ntable_aeroports\n\n\n\n\nRéponse question 2\ntable_aeroports &lt;- table_aeroports %&gt;%\n  cols_hide(columns = starts_with(\"apt\"))\ntable_aeroports\n\n\n\n\nRéponse question 3\ntable_aeroports &lt;- table_aeroports %&gt;%\n  fmt_number(columns = starts_with(\"pax\"), suffixing = TRUE)\ntable_aeroports\n\n\n\n\nRéponse question 4\ntable_aeroports &lt;- table_aeroports %&gt;%\n  fmt_markdown(columns = \"name_clean\")\ntable_aeroports\n\n\n\n\nRéponse question 5\ntable_aeroports &lt;- table_aeroports %&gt;%\n  cols_label(\n    name_clean = md(\"**Aéroport**\"),\n    paxdep = md(\"**Départs**\"),\n    paxarr = md(\"**Arrivée**\"),\n    paxtra = md(\"**Transit**\")\n  ) %&gt;%\n  tab_header(\n    title = md(\"**Statistiques de fréquentation**\"),\n    subtitle = md(\"Classement des aéroports\")\n  ) %&gt;%\n  tab_style(\n    style = cell_fill(color = \"powderblue\"),\n    locations = cells_title()\n  ) %&gt;%\n  tab_source_note(source_note = md(\"_Source: DGAC, à partir des données sur data.gouv.fr_\"))\n  \ntable_aeroports\n\n\n\n\nRéponse question 6\ntable_aeroports &lt;- table_aeroports %&gt;%\n  opt_interactive()\ntable_aeroports\n\n\n\n\n\n\nStatistiques de fréquentation\nClassement des aéroports\n\n\n\n\n\n\nSource: DGAC, à partir des données sur data.gouv.fr\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolution suggérée pour l’exercice ci-dessus\n\ntable_gt = (\n  GT(stats_aeroports.head(15))\n  .cols_hide(columns = stats_aeroports.filter(like = \"apt\").columns.tolist())\n  .fmt_number(columns = stats_aeroports.filter(like = \"pax\").columns.tolist(), compact = True)\n  .fmt_markdown(columns = \"name_clean\")\n  .cols_label(\n    name_clean = md(\"**Aéroport**\"),\n    paxdep = md(\"**Départs**\"),\n    paxarr = md(\"**Arrivée**\"),\n    paxtr = md(\"**Transit**\")\n  ) \n  .tab_header(\n    title = md(\"**Statistiques de fréquentation**\"),\n    subtitle = md(\"Classement des aéroports\")\n  )\n  .tab_source_note(\n    source_note = md(\"_Source: DGAC, à partir des données sur data.gouv.fr_\")\n  )\n)\n\n\n\n\nNous proposons de transformer ce code en fonction, cela facilitera l’utilisation ultérieure de celui-ci dans notre application.\n\n\n\n\n\n\n Exercice 4c (optionnel): transformer en fonction notre chaîne gt\n\n\n\n\n\nCet exercice est optionnel. Transformer le code ci-dessus en fonction qui sera enregistrée dans R/tables.R () ou src/tables.py (). Mettre à jour main.R ou main.py pour utiliser ceci dans votre application.\n\n\n\n\n\n\n\n\n\nCode de R/tables.R\n\n\n\nR/tables.R\n\ncreate_table_airports &lt;- function(stats_aeroports){\n\n  stats_aeroports_table &lt;- stats_aeroports %&gt;%\n    mutate(name_clean = paste0(str_to_sentence(apt_nom), \" _(\", apt, \")_\")\n    ) %&gt;%\n    select(name_clean, everything())\n    \n  table_aeroports &lt;- gt(stats_aeroports_table)\n  \n  table_aeroports &lt;- table_aeroports %&gt;%\n    cols_hide(columns = starts_with(\"apt\"))\n  \n  table_aeroports &lt;- table_aeroports %&gt;%\n    fmt_number(columns = starts_with(\"pax\"), suffixing = TRUE)\n  \n  table_aeroports &lt;- table_aeroports %&gt;%\n    fmt_markdown(columns = \"name_clean\")\n  \n  table_aeroports &lt;- table_aeroports %&gt;%\n    cols_label(\n      name_clean = md(\"**Aéroport**\"),\n      paxdep = md(\"**Départs**\"),\n      paxarr = md(\"**Arrivée**\"),\n      paxtra = md(\"**Transit**\")\n    ) %&gt;%\n    tab_header(\n      title = md(\"**Statistiques de fréquentation**\"),\n      subtitle = md(\"Classement des aéroports\")\n    ) %&gt;%\n    tab_style(\n      style = cell_fill(color = \"powderblue\"),\n      locations = cells_title()\n    ) %&gt;%\n    tab_source_note(source_note = md(\"_Source: DGAC, à partir des données sur data.gouv.fr_\"))\n  \n  table_aeroports &lt;- table_aeroports %&gt;%\n    opt_interactive()\n  \n  return(table_aeroports)\n\n}\n\n\n\n\nCode de main.R\n\n\n\nmain.R\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(gt)\nlibrary(leaflet)\n\nsource(\"correction/R/import_data.R\")\nsource(\"correction/R/create_data_list.R\")\nsource(\"correction/R/clean_dataframe.R\")\nsource(\"correction/R/divers_functions.R\")\nsource(\"correction/R/tables.R\")\nsource(\"correction/R/figures.R\")\n\nYEARS_LIST  &lt;- as.character(2018:2022)\nMONTHS_LIST &lt;- 1:12\nyear &lt;- YEARS_LIST[1]\nmonth &lt;- MONTHS_LIST[1]\n\n\n# Load data ----------------------------------\nurls &lt;- create_data_list(\"./sources.yml\")\n\n\npax_apt_all &lt;- import_airport_data(unlist(urls$airports))\npax_cie_all &lt;- import_compagnies_data(unlist(urls$compagnies))\npax_lsn_all &lt;- import_liaisons_data(unlist(urls$liaisons))\n\nairports_location &lt;- st_read(urls$geojson$airport)\n\nliste_aeroports &lt;- unique(pax_apt_all$apt)\ndefault_airport &lt;- liste_aeroports[1]\n\n# OBJETS NECESSAIRES A L'APPLICATION ------------------------\n\ntrafic_aeroports &lt;- pax_apt_all %&gt;%\n  mutate(trafic = apt_pax_dep + apt_pax_tr + apt_pax_arr) %&gt;%\n  filter(apt %in% default_airport) %&gt;%\n  mutate(\n    date = as.Date(paste(anmois, \"01\", sep=\"\"), format = \"%Y%m%d\")\n  )\n\nstats_aeroports &lt;- summary_stat_airport(\n  create_data_from_input(pax_apt_all, year, month)\n)\n\n\n# VALORISATIONS ----------------------------------------------\n\nfigure_plotly &lt;- plot_airport_line(trafic_aeroports,default_airport)\n\ntable_airports &lt;- create_table_airports(stats_aeroports)\n\n\n\n\n\n\nCode de src/tables.py\n\n\n\nstc/tables.py\n\nfrom great_tables import GT, md\n\ndef create_table_airports(stats_aeroports):\n\n    stats_aeroports['name_clean'] = stats_aeroports['apt_nom'].str.title() + \" _(\" + stats_aeroports['apt'] + \")_\"\n    stats_aeroports = stats_aeroports[ ['name_clean'] + [ col for col in stats_aeroports.columns if col != 'name_clean' ] ]\n\n    table_gt = (\n        GT(stats_aeroports.head(15))\n        .cols_hide(columns = stats_aeroports.filter(like = \"apt\").columns.tolist())\n        .fmt_number(columns = stats_aeroports.filter(like = \"pax\").columns.tolist(), compact = True)\n        .fmt_markdown(columns = \"name_clean\")\n        .cols_label(\n            name_clean = md(\"**Aéroport**\"),\n            paxdep = md(\"**Départs**\"),\n            paxarr = md(\"**Arrivée**\"),\n            paxtr = md(\"**Transit**\")\n        ) \n        .tab_header(\n            title = md(\"**Statistiques de fréquentation**\"),\n            subtitle = md(\"Classement des aéroports\")\n        )\n        .tab_source_note(source_note = md(\"_Source: DGAC, à partir des données sur data.gouv.fr_\"))\n    )\n\n    return table_gt\n\n\n\n\nCode de main.py\n\n\n\nmain.py\n\nimport pandas as pd\nimport geopandas as gpd\nimport plotly.express as px\n\nimport src.import_data as sid\nfrom src.create_data_list import create_data_list\nfrom src.divers_functions import (\n  create_data_from_input,\n  summary_stat_airport\n)\nfrom src.tables import create_table_airports\n\n\nYEARS_LIST = [str(year) for year in range(2018, 2023)]\nMONTHS_LIST = list(range(1, 13))\nyear = YEARS_LIST[0]\nmonth = MONTHS_LIST[0]\n\n# Load data ----------------------------------\nurls = create_data_list(\"./sources.yml\")\n\n\npax_apt_all = sid.import_airport_data(urls['airports'].values())\npax_cie_all = sid.import_airport_data(urls['compagnies'].values())\npax_lsn_all = sid.import_airport_data(urls['liaisons'].values())\n\n\nairports_location = gpd.read_file(\n    urls['geojson']['airport']\n)\n\n\nliste_aeroports = pax_apt_all['apt'].unique()\ndefault_airport = liste_aeroports[0]\n\n\n# OBJETS NECESSAIRES A L'APPLICATION ------------------------\n\npax_apt_all['trafic'] = pax_apt_all['apt_pax_dep'] + \\\n  pax_apt_all['apt_pax_tr'] + \\\n  pax_apt_all['apt_pax_arr']\n\ntrafic_aeroports = (\n  pax_apt_all\n  .loc[pax_apt_all['apt'] == default_airport]\n)\ntrafic_aeroports['date'] = pd.to_datetime(\n  trafic_aeroports['anmois'] + '01', format='%Y%m%d'\n)\n\nstats_aeroports = summary_stat_airport(\n  create_data_from_input(pax_apt_all, year, month)\n)\n\n\n# VALORISATIONS ----------------------------------------------\n\nfrom src.figures import plot_airport_line\n\nfigure_plotly = plot_airport_line(trafic_aeroports, default_airport)\n\ntable_airports = create_table_airports(stats_aeroports)"
  },
  {
    "objectID": "index.html#valorisation-3-carte-des-aéroports",
    "href": "index.html#valorisation-3-carte-des-aéroports",
    "title": "Un tableau de bord du trafic aérien avec  ou ",
    "section": "4.5 Valorisation 3: Carte des aéroports",
    "text": "4.5 Valorisation 3: Carte des aéroports\nLa troisième valorisation qui sera intégrée dans l’application web est une carte interactive du trafic de nos aéroports. Cette carte va être assez basique. Si vous désirez mettre en oeuvre des visualisations plus complexes, vous pouvez tout à fait le faire.\nPour cet exercice, nous allons fixer une date pour prototyper notre code. Cela nous facilitera la transformation ultérieure en fonction.\n\n\n\n\n\nmonth &lt;- 1\nyear &lt;- 2019\n\nVoici également une palette de couleurs qui sera utile à la fin de l’exercice.\n\npalette &lt;- c(\"green\", \"blue\", \"red\")\n\n\n\n\nmonth = 1\nyear = 2019\n\nVoici également une palette de couleurs qui sera utile à la fin de l’exercice.\n\npalette = c(\"green\", \"blue\", \"red\")\n\n\n\n\n\n\n\n\n\n\n Exercice 5: carte aérienne du trafic aéroportuaire\n\n\n\n\n\n\nCréer un dataframe trafic_date en ne conservant que les observations de pax_apt_all égales à un certain mois et une certaine année (vous pouvez vous inspirer d’un filtre fait précédemment).\nAjouter ces informations à la table airports_location en faisant une jointure sur les variables Code.OACI et apt, respectivement. Nommer ce dataframe trafic_aeroports.\nA partir de l’exemple de démarrage de leaflet  ou de l’exemple canonique folium (), créer une carte interactive qui affiche, lorsqu’on clique sur l’un des marqueurs, le nom de l’aéroport et sa fréquentation.\nCréer une variable nommée volume qui classe chaque observation dans son tercile et transforme la valeur en couleur à partir de palette.\n\nReproduire une carte similaire à celle présentée plus bas:\n\nEn , vous aurez besoin de la fonction addAwesomeMarkers et de l’exemple de code ci-dessous:\n\n\n# Aide pour l'exemple R\nicons &lt;- awesomeIcons(\n  icon = 'plane',\n  iconColor = 'black',\n  library = 'fa',\n  markerColor = trafic_aeroports$color\n)\n* En , il vous suffit de modifier les paramètres de l'argument `icon`\n\n\n\n\n\n\nSubtilité par rapport à l’exemple de la documentation pour \n\n\n\n\n\nPar rapport à l’exemple dans la documentation, il faut légèrement modifier le code de sorte à faire icon=icons[] et non icon = icons.\n\n\n\n\n\n\n\n\n\n\n\n\nQuestion 1\ntrafic_date &lt;- pax_apt_all %&gt;%\n  mutate(\n    date = as.Date(paste(anmois, \"01\", sep=\"\"), format = \"%Y%m%d\")\n  ) %&gt;%\n  filter(mois == month, an == year)\ntrafic_aeroports &lt;- airports_location %&gt;%\n  inner_join(trafic_date, by = c(\"Code.OACI\" = \"apt\"))\n\n\n\n\nQuestion 2\nlibrary(leaflet)\n  \nleaflet(trafic_aeroports) %&gt;% addTiles() %&gt;%\n  addMarkers(popup = ~paste0(Nom, \": \", trafic)) \n\n\n\n\nQuestion 3\ntrafic_aeroports &lt;- trafic_aeroports %&gt;%\n  mutate(\n    volume = ntile(trafic, 3)\n) %&gt;%\n  mutate(\n    color = palette[volume]\n  )\n\n\n\n\nQuestion 4\nicons &lt;- awesomeIcons(\n  icon = 'plane',\n  iconColor = 'black',\n  library = 'fa',\n  markerColor = trafic_aeroports$color\n)\n\n\ncarte_interactive &lt;- leaflet(trafic_aeroports) %&gt;% addTiles() %&gt;%\n  addAwesomeMarkers(\n  icon=icons[],\n  label=~paste0(Nom, \"\", \" (\",Code.OACI, \") : \", trafic, \" voyageurs\")\n)\n\n\n\n\nVoir la solution de l’exercice suivant\n\n\n\n\n\n\n\n\n\nComme précédemment, nous proposons de transformer la production de cette carte en fonction, cela nous permettra d’avoir une application légère. Là encore c’est un exercice optionnel mais intéressant à faire pour découvrir la logique de la programmation fonctionnelle.\n\n\n\n\n\n\n Exercice 5b (optionnel): une fonction pour notre carte\n\n\n\n\n\n\nCréer une fonction map_leaflet_airport avec les arguments df, airports_location, month et year produisant la carte. Insérer celle-ci dans le script R/figures.R (dans src/figures.py pour Python).\nMettre à jour main.R ou main.py pour utiliser cette fonction dans votre chaine. N’oubliez pas de définir month et year dans votre script.\n\n\n\n\n\n\n\n\n\n\nCode de R/figures.R à reprendre\n\n\n\nR/figures.R (fin du fichier)\n\n\nmap_leaflet_airport &lt;- function(df, airports_location, months, years){\n  \n  palette &lt;- c(\"green\", \"blue\", \"red\")\n\n  trafic_date &lt;- df %&gt;%\n    mutate(\n      date = as.Date(paste(anmois, \"01\", sep=\"\"), format = \"%Y%m%d\")\n    ) %&gt;%\n    filter(mois == months, an == years)\n  \n  trafic_aeroports &lt;- airports_location %&gt;%\n    select(Code.OACI, Nom, geometry) %&gt;% \n    inner_join(trafic_date, by = c(\"Code.OACI\" = \"apt\"))\n  \n  \n  trafic_aeroports &lt;- trafic_aeroports %&gt;%\n    mutate(\n      trafic = apt_pax_dep + apt_pax_tr + apt_pax_arr,\n      volume = ntile(trafic, 3)\n    ) %&gt;%\n    mutate(\n      color = palette[volume]\n    )  \n  \n  icons &lt;- awesomeIcons(\n    icon = 'plane',\n    iconColor = 'black',\n    library = 'fa',\n    markerColor = trafic_aeroports$color\n  )\n  \n  carte_interactive &lt;- leaflet(trafic_aeroports) %&gt;% addTiles() %&gt;%\n    addAwesomeMarkers(\n      icon=icons[],\n      label=~paste0(Nom, \"\", \" (\",Code.OACI, \") : \", trafic, \" voyageurs\")\n    )\n  \n  return(carte_interactive)\n}\n\n\n\n\n\nCode de main.R à reprendre\n\n\n\nmain.R\n\nlibrary(readr)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(gt)\nlibrary(leaflet)\n\nsource(\"correction/R/import_data.R\")\nsource(\"correction/R/create_data_list.R\")\nsource(\"correction/R/clean_dataframe.R\")\nsource(\"correction/R/divers_functions.R\")\nsource(\"correction/R/tables.R\")\nsource(\"correction/R/figures.R\")\n\nYEARS_LIST  &lt;- as.character(2018:2022)\nMONTHS_LIST &lt;- 1:12\nyear &lt;- YEARS_LIST[1]\nmonth &lt;- MONTHS_LIST[1]\n\n\n# Load data ----------------------------------\nurls &lt;- create_data_list(\"./sources.yml\")\n\n\npax_apt_all &lt;- import_airport_data(unlist(urls$airports))\npax_cie_all &lt;- import_compagnies_data(unlist(urls$compagnies))\npax_lsn_all &lt;- import_liaisons_data(unlist(urls$liaisons))\n\nairports_location &lt;- st_read(urls$geojson$airport)\n\nliste_aeroports &lt;- unique(pax_apt_all$apt)\ndefault_airport &lt;- liste_aeroports[1]\n\n\n# OBJETS NECESSAIRES A L'APPLICATION ------------------------\n\ntrafic_aeroports &lt;- pax_apt_all %&gt;%\n  mutate(trafic = apt_pax_dep + apt_pax_tr + apt_pax_arr) %&gt;%\n  filter(apt %in% default_airport) %&gt;%\n  mutate(\n    date = as.Date(paste(anmois, \"01\", sep=\"\"), format = \"%Y%m%d\")\n  )\n\nstats_aeroports &lt;- summary_stat_airport(\n  create_data_from_input(pax_apt_all, year, month)\n)\nstats_liaisons  &lt;- summary_stat_liaisons(\n  create_data_from_input(pax_lsn_all, year, month)\n)\n\n\n# VALORISATIONS ----------------------------------------------\n\nfigure_plotly &lt;- plot_airport_line(trafic_aeroports,default_airport)\n\ntable_airports &lt;- create_table_airports(stats_aeroports)\n\ncarte_interactive &lt;- map_leaflet_airport(\n  pax_apt_all, airports_location,\n  month, year\n)\n\n\n\n\n\n\nCode de src/figures.py à reprendre\n\n\n\nsrc/figures.py (fin du fichier)\n\n\n\n\n\n\nCode de main.py à reprendre\n\n\n\nmain.py\n\nimport pandas as pd\nimport geopandas as gpd\nimport plotly.express as px\n\nimport src.import_data as sid\nfrom src.create_data_list import create_data_list\nfrom src.divers_functions import (\n  create_data_from_input,\n  summary_stat_airport\n)\nfrom src.tables import create_table_airports\nfrom src.figures import plot_airport_line, map_leaflet_airport\n\n\nYEARS_LIST = [str(year) for year in range(2018, 2023)]\nMONTHS_LIST = list(range(1, 13))\nyear = YEARS_LIST[0]\nmonth = MONTHS_LIST[0]\n\n# Load data ----------------------------------\nurls = create_data_list(\"./sources.yml\")\n\n\npax_apt_all = sid.import_airport_data(urls['airports'].values())\npax_cie_all = sid.import_airport_data(urls['compagnies'].values())\npax_lsn_all = sid.import_airport_data(urls['liaisons'].values())\n\nairports_location = gpd.read_file(\n    urls['geojson']['airport']\n)\n\n\nliste_aeroports = pax_apt_all['apt'].unique()\ndefault_airport = liste_aeroports[0]\n\n\n# OBJETS NECESSAIRES A L'APPLICATION ------------------------\n\npax_apt_all['trafic'] = pax_apt_all['apt_pax_dep'] + \\\n  pax_apt_all['apt_pax_tr'] + \\\n  pax_apt_all['apt_pax_arr']\n\ntrafic_aeroports = (\n  pax_apt_all\n  .loc[pax_apt_all['apt'] == default_airport]\n)\ntrafic_aeroports['date'] = pd.to_datetime(\n  trafic_aeroports['anmois'] + '01', format='%Y%m%d'\n)\n\nstats_aeroports = summary_stat_airport(\n  create_data_from_input(pax_apt_all, year, month)\n)\n\n\n# VALORISATIONS ----------------------------------------------\n\nfigure_plotly = plot_airport_line(trafic_aeroports, default_airport)\n\ntable_airports = create_table_airports(stats_aeroports)\n\ncarte_interactive = map_leaflet_airport(\n  pax_apt_all, airports_location,\n  month, year\n)"
  },
  {
    "objectID": "index.html#conteneurisation-de-lapplication",
    "href": "index.html#conteneurisation-de-lapplication",
    "title": "Un tableau de bord du trafic aérien avec  ou ",
    "section": "6.1 Conteneurisation de l’application",
    "text": "6.1 Conteneurisation de l’application\nPour déployer son application, la première étape consiste à la conteneuriser, ce qui signifie la mettre dans une sorte de boîte virtuelle contenant tout ce dont l’application a besoin pour fonctionner. Le conteneur sépare l’application de son environnement extérieur, ce qui permet d’éviter les conflits avec d’autres applications ou dépendances sur le même système. Puisque le conteneur contient tout ce dont l’application a besoin (comme les bibliothèques et les dépendances), l’application peut être déplacée et exécutée sur n’importe quel système qui supporte les conteneurs, sans se soucier des différences entre ces systèmes.\nAinsi, conteneuriser une application permet de la rendre plus facile à déployer, plus fiable et plus portable (en utilisant efficacement les ressources du système). Docker est un outil populaire pour créer et gérer des conteneurs. Le fichier Dockerfile contient le code nécessaire pour construire l’image Docker de l’application finale située dans le répertoire correction. Vous pouvez consulter la documentation Docker pour tenter de comprendre comment l’image est construite.\nNous ne vous demandons pas de construire l’image vous-même, l’image est déjà publique sur Dockerhub et peut-être utilisée pour déployer l’application. Néanmoins, il est intéressant, pour comprendre la logique de fonctionnement de Docker, de regarder la recette de construction de cette image\n\n\n\n\n\n\nDockerfile\n\nFROM inseefrlab/onyxia-rstudio:r4.3.2-2024.02.13\n\n# Add files necessary for the running app\nADD correction/global.R .\nADD correction/ui.R .\nADD correction/server.R .\nADD correction/sources.yml .\nCOPY correction/R R/\nADD renv.lock .\nADD renv .\n\n\n# Expose port where shiny app will broadcast\nARG SHINY_PORT=3838\nEXPOSE $SHINY_PORT\nRUN echo \"local({options(shiny.port = ${SHINY_PORT}, shiny.host = '0.0.0.0')})\" &gt;&gt; /usr/local/lib/R/etc/Rprofile.site\n\nRUN Rscript -e \"renv::restore()\"\n\n# Endpoint\nCMD [\"Rscript\", \"-e\", \"shiny::runApp()\"]\n\n\n\n\n\nDockerfile\n\nFROM inseefrlab/onyxia-jupyter-python:py3.10.9\n\n# Add files necessary for the running app\nADD correction/app.py .\nADD correction/sources.yml .\nADD requirements.txt .\n\n# Move directories to the project root\nCOPY correction/src src/\nCOPY correction/.streamlit .streamlit/\n\n\n# Install dependencies\nRUN pip install -r requirements.txt\n\nEXPOSE 8000\nCMD [\"streamlit\", \"run\", \"app.py\", \"--server.port=8000\", \"--server.address=0.0.0.0\"]\n\n\n\n\nLes principales étapes de cette construction d’image sont les suivantes :\n\n1️⃣ On part d’une image de base qui correspond à celle dans laquelle on a développé notre application et qui fonctionnait. On pourrait partir d’un environnement plus minimaliste (une machine Linux avec seulement R installé, comme les images rocker) mais nous aurions peut-être à installer des librairies système en plus par un processus d’essai-erreur coûteux en temps.\n\n\n\n\n\n\n\nPartie du Dockerfile en question\n\n\n\nDockerfile\n\nFROM inseefrlab/onyxia-rstudio:r4.3.2-2024.02.13\n\n\n\n\n\n\nPartie du Dockerfile en question\n\n\n\nDockerfile\n\nFROM inseefrlab/onyxia-jupyter-python:py3.10.9\n\n\n\n\n\n\n2️⃣ On ajoute dans le conteneur les fichiers indispensables au fonctionnement de notre application. Le conteneur, par défaut, n’a pas les fichiers de notre projet, on doit donc dire à Docker quels fichiers on désire avoir dans notre application.\n\n\n\n\n\n\n\nPartie du Dockerfile en question\n\n\n\nDockerfile\n\n# Add files necessary for the running app\nADD correction/global.R .\nADD correction/ui.R .\nADD correction/server.R .\nADD correction/sources.yml .\nCOPY correction/R R/\nADD renv.lock .\nADD renv .\n\n\n\n\n\n\nPartie du Dockerfile en question\n\n\n\nDockerfile\n\n# Add files necessary for the running app\nADD correction/app.py .\nADD correction/sources.yml .\nADD requirements.txt .\n\n# Move directories to the project root\nCOPY correction/src src/\nCOPY correction/.streamlit .streamlit/\n\n\n\n\n\n\n3️⃣ On définit des paramètres sur le routage de notre application dans le conteneur (seulement nécessaire pour la solution ). Ces paramètres nous seront utiles ultérieurement, lors du déploiement.\n\n\n\n\n\n\n\nPartie du Dockerfile en question\n\n\n\nDockerfile\n\n# Expose port where shiny app will broadcast\nARG SHINY_PORT=3838\nEXPOSE $SHINY_PORT\nRUN echo \"local({options(shiny.port = ${SHINY_PORT}, shiny.host = '0.0.0.0')})\" &gt;&gt; /usr/local/lib/R/etc/Rprofile.site\n\n\n\n\nCette étape n’est pas nécessaire.\n\n\n\n\n4️⃣ On restaure l’environnement avec renv () ou pip (). De cette manière, on est assuré que l’application aura le même environnement que celui que nous avons prévu lors de la phase de développement.\n\n\n\n\n\n\n\nPartie du Dockerfile en question\n\n\n\nDockerfile\n\nRUN Rscript -e \"renv::restore()\"\n\n\n\n\n\n\nPartie du Dockerfile en question\n\n\n\nDockerfile\n\n# Install dependencies\nRUN pip install -r requirements.txt\n\n\n\n\n\n\n5️⃣ On définit la commande qui sera exécutée au lancement de notre application. En l’occurrence, c’est une ligne de commande Linux pour lancer l’application Shiny ou Streamlit\n\n\n\n\n\n\n\nPartie du Dockerfile en question\n\n\n\nDockerfile\n\n# Endpoint\nCMD [\"Rscript\", \"-e\", \"shiny::runApp()\"]\n\n\n\n\n\n\nPartie du Dockerfile en question\n\n\n\nDockerfile\n\nEXPOSE 8000\nCMD [\"streamlit\", \"run\", \"app.py\", \"--server.port=8000\", \"--server.address=0.0.0.0\"]\n\n\n\n\n\nSi le Dockerfile est la recette pour créer notre application, où se trouve la cuisine pour préparer notre plat ? En général, on passe par des systèmes d’intégration continue, des serveurs mis à disposition en complément de forges Git pour tester le Dockerfile. Pour en savoir plus sur l’intégration continue, vous pouvez consulter le cours de 3e année de l’ENSAE.\nVoici le fichier .github/workflows/app.yaml qui contient la suite d’instruction donnée aux serveurs de Github pour exécuter notre chaine de production de l’image Docker. Celui-ci est quasiment une reprise mot pour mot de l’exemple de la documentation Github.\n\n\nLe workflow Github en question ( et )\n\n\n\n.github/workflows/app.yaml\n\nname: Dockerize\n\non:\n  push:\n    tags:\n      - \"*\"\n    branches:\n      - main\n\njobs:\n  docker-shiny:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Docker meta\n        id: docker_meta\n        uses: docker/metadata-action@v5\n        with:\n          images: inseefrlab/funathon2024-sujet2\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v3\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n      - name: Login to DockerHub\n        if: github.event_name != 'pull_request'\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      - name: Build and push\n        uses: docker/build-push-action@v6\n        with:\n          context: .\n          file: ./docker/Dockerfile\n          push: ${{ github.event_name != 'pull_request' }}\n          tags: |\n            ${{ steps.docker_meta.outputs.tags }}\n            ${{ github.ref == 'refs/heads/main' && 'inseefrlab/funathon2024-sujet2:shiny-test2' || '' }}\n          labels: ${{ steps.docker_meta.outputs.labels }}\n      - name: Image digest\n        run: echo ${{ steps.docker_build.outputs.digest }}\n  docker-streamlit:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Docker meta\n        id: docker_meta\n        uses: docker/metadata-action@v5\n        with:\n          images: inseefrlab/funathon2024-sujet2\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v3\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n      - name: Login to DockerHub\n        if: github.event_name != 'pull_request'\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      - name: Build and push\n        uses: docker/build-push-action@v6\n        with:\n          context: .\n          file: ./docker/Dockerfile_python\n          push: ${{ github.event_name != 'pull_request' }}\n          tags: |\n            ${{ steps.docker_meta.outputs.tags }}\n            ${{ github.ref == 'refs/heads/main' && 'inseefrlab/funathon2024-sujet2:streamlit-test2' || '' }}\n          labels: ${{ steps.docker_meta.outputs.labels }}\n      - name: Image digest\n        run: echo ${{ steps.docker_build.outputs.digest }}"
  },
  {
    "objectID": "index.html#utilisation-de-limage-docker-pour-mettre-à-disposition-le-shiny-ou-streamlit",
    "href": "index.html#utilisation-de-limage-docker-pour-mettre-à-disposition-le-shiny-ou-streamlit",
    "title": "Un tableau de bord du trafic aérien avec  ou ",
    "section": "6.2 Utilisation de l’image Docker pour mettre à disposition le Shiny ou Streamlit",
    "text": "6.2 Utilisation de l’image Docker pour mettre à disposition le Shiny ou Streamlit\nNous avons créé une image Docker qui est disponible sur Dockerhub, le réseau social de Docker. Pour rendre celle-ci vivante, nous devons la déployer dans un conteneur.\n\n\n\n\n\n\n Exercice 7 : Déploiement de l’application Shiny\n\n\n\n\n\nL’image peut à présent être récupérée et déployée. Dans notre cas, on va la déployer sur un cluster Kubernetes, l’infrastructure sous-jacente du SSP Cloud. Le fonctionnement de Kubernetes est technique et nous ne rentrerons pas dans les détails ici. Les fichiers nécessaires au déploiement se trouvent dans un dépôt séparé (https://github.com/InseeFrLab/funathon2024_sujet2_cd), nommé dépôt Git-ops.\nAfin de déployer l’application, suivre les instructions suivantes :\n\nOuvrir un Terminal;\nClôner le dépôt (git clone https://github.com/InseeFrLab/funathon2024_sujet2_cd)\nSe placer à la racine du projet (cd funathon2024_sujet2_cd);\nInspecter les fichiers shiny/deployment.yml, shiny/service.yml et shiny/ingress.yml (parcours ) ou streamlit/deployment.yml, streamlit/service.yml et streamlit/ingress.yml (parcours ) et repérer les éléments suivants :\n\nL’emplacement où est spécifié l’image à déployer;\nL’emplacement où sont spécifiées les ressources computationnelles allouées;\nL’emplacement où est spécifiée l’URL à laquelle sera exposée l’application sur Internet. La modifier (à 2 reprises) pour y indiquer une adresse personalisée pour le déploiement. Seule contrainte, elle doit être de la forme *.lab.sspcloud.fr;\n\nAppliquer les contrats Kubernetes avec la commande kubectl apply -f shiny/ ou kubectl apply -f streamlit/ selon le langage utilisé ;\nVérifier le lancement du conteneur avec la commande kubectl get pods. Le nom associé devrait être de la forme funathon2024-sujet2-deployment-*;\nAttendre que le conteneur obtienne le statut Running.\nCopier le nom associé à votre service et faire kubectl logs &lt;nom_copié&gt;.\n\n\nEntrer dans un navigateur l’URL spécifiée dans le fichier streamlit/ingress.yaml ou shiny/ingress.yaml, et vérifier que l’application fonctionne correctement ! Jouer avec et observer, dans le terminal que vous aviez ouvert, l’évolution de vos logs quand vous faites une action."
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Un tableau de bord du trafic aérien avec  ou ",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPour le créer, vous pouvez taper F1 et dans la barre qui s’ouvre, taper notebook et cliquer sur Create: New Jupyter Notebook. Enregistrer le fichier↩︎\nCes fichiers ne sont pas générés manuellement. Ce sont des outils adaptés (renv pour R, pip pour Python) qui font ce travail de versionnage de l’environnement.↩︎\nSi vous utilisez renv dans vos futurs projets, ce que nous vous recommandons, cette commande n’est pas à inscrire dans vos scripts. Vous pouvez indiquer que cette commande est nécessaire dans le README de votre projet.↩︎\nSi vous êtes peu familier avec ce type de fichiers, vous pouvez consulter la fiche utilitR sur le sujet ()↩︎\nSi vous êtes peu familier avec les données géographiques, vous pouvez retenir l’idée qu’il s’agit de données traditionnelles auxquelles s’ajoute une dimension spatiale. Cette dernière vise à localiser les données sur la terre. La localisation se fait dans un espace à deux dimensions (espace cartésien) alors que notre planète est une sphère en trois dimensions. Le principe d’un système de projection est de faire ce passage en deux dimensions des positions. Le plus connu est le système GPS, qui est un héritier lointain de la représentation du monde par Mercator. Ce système est connu sous le nom de WGS 84 et porte le code EPSG 4326. L’autre système à retenir est le Lambert 93 (code EPSG 2154) qui est la projection légale en France (celle-ci, a contrario du Mercator, ne déforme pas la France sur une carte). Pour en savoir plus sur les systèmes de représentation, les avantages et inconvénients de chacun, il existe de nombreuses ressources en ligne. Des éléments introductifs, et des démonstrations interactives, en lien avec la librairie Geopandas de Python sont disponibles ici.↩︎\nVous perdrez la mise en forme du header du tableau qui n’est pas conciliable avec l’interactivité.↩︎"
  }
]